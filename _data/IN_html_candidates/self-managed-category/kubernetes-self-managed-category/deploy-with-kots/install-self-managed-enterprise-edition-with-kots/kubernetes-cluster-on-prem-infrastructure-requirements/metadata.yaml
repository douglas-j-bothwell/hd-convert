type: article
article_id: d5lptkp5ow
user_id: u10w77i7vp
category_id: ody8r3ad8f
author:
  name: Katherine Enos
  profile_image: https://www.gravatar.com/avatar/854cdb03d99ded9ecd30fa9cf06a5298?d=mm&s=150
title: Infrastructure
slug: kubernetes-cluster-on-prem-infrastructure-requirements
description: This document lists the infrastructure requirements for installing Harness
  Self-Managed Enterprise Edition.
short_version: This document lists the infrastructure requirements for installing
  Harness Self-Managed Enterprise Edition
tags:
- on-premises
show_toc: true
is_private: false
is_published: true
is_featured: false
stale_status:
  is_stale: false
  reason: ""
  source: API
  triggered_at: 2022-08-29T22:51:22.028145Z
  expires_at: null
permission_groups: []
multilingual:
- language_code: en
  title: Infrastructure
  description: This document lists the infrastructure requirements for installing
    Harness Self-Managed Enterprise Edition.
  short_version: This document lists the infrastructure requirements for installing
    Harness Self-Managed Enterprise Edition
  body: '<p>Installation of Harness Self-Managed Enterprise Edition in an existing
    Kubernetes cluster requires the following infrastructure. </p><h3>Production Environment</h3><p>Self-Managed
    Enterprise Edition NextGen is installed as an application on an existing Self-Managed
    Enterprise Edition FirstGen installation.</p><p>The following tables list the
    resource requirements for the installation of Self-Managed Enterprise Edition
    in the production environment.</p><h4>Self-Managed Enterprise Edition FirstGen</h4><table><tbody><tr><td><p><strong>Microservice</strong></p></td><td><p><strong>Pods</strong></p></td><td><p><strong>CPU
    / Pod</strong></p></td><td><p><strong>Memory / Pod</strong></p></td><td><p><strong>Total
    CPU</strong></p></td><td><p><strong>Total Memory</strong></p></td></tr><tr><td><p>Manager</p></td><td><p>2</p></td><td><p>2</p></td><td><p>4</p></td><td><p>4</p></td><td><p>8</p></td></tr><tr><td><p>Verification</p></td><td><p>2</p></td><td><p>1</p></td><td><p>3</p></td><td><p>2</p></td><td><p>6</p></td></tr><tr><td><p>Machine
    Learning Engine</p></td><td><p>1</p></td><td><p>8</p></td><td><p>2</p></td><td><p>8</p></td><td><p>2</p></td></tr><tr><td><p>UI</p></td><td><p>2</p></td><td><p>0.25</p></td><td><p>0.25</p></td><td><p>0.5</p></td><td><p>0.5</p></td></tr><tr><td><p>MongoDB</p></td><td><p>3</p></td><td><p>4</p></td><td><p>8</p></td><td><p>12</p></td><td><p>24</p></td></tr><tr><td><p>Proxy</p></td><td><p>1</p></td><td><p>0.5</p></td><td><p>0.5</p></td><td><p>0.5</p></td><td><p>0.5</p></td></tr><tr><td><p>Ingress</p></td><td><p>2</p></td><td><p>0.25</p></td><td><p>0.25</p></td><td><p>0.5</p></td><td><p>0.5</p></td></tr><tr><td><p>TimescaleDB</p></td><td><p>3</p></td><td><p>2</p></td><td><p>8</p></td><td><p>6</p></td><td><p>24</p></td></tr><tr><td><p>KOTS
    Admin Pods</p></td><td><p> </p></td><td><p> </p></td><td><p> </p></td><td><p>4</p></td><td><p>8</p></td></tr><tr><td><p><strong>Total</strong></p></td><td><p><strong> </strong></p></td><td><p><strong> </strong></p></td><td><p><strong> </strong></p></td><td><p><strong>37.5</strong></p></td><td><p><strong>73.5</strong></p></td></tr></tbody></table><p></p><p>The
    compute resources listed for the KOTS admin pods support a full stack. In an existing
    cluster, the requirements for KOTS are usually lower.</p><h4>Self-Managed Enterprise
    Edition NextGen</h4><table><tbody><tr><td><p><strong>Microservice</strong></p></td><td><p><strong>Pods</strong></p></td><td><p><strong>CPU
    / Pod</strong></p></td><td><p><strong>Memory / Pod</strong></p></td><td><p><strong>Total
    CPU</strong></p></td><td><p><strong>Total Memory</strong></p></td></tr><tr><td><p>Log
    Minio</p></td><td><p>1</p></td><td><p>1</p></td><td><p>4Gi</p></td><td><p>1</p></td><td><p>4Gi</p></td></tr><tr><td><p>Log
    service</p></td><td><p>1</p></td><td><p>1</p></td><td><p>3Gi</p></td><td><p>1</p></td><td><p>3Gi</p></td></tr><tr><td><p>SCM</p></td><td><p>1</p></td><td><p>0.1</p></td><td><p>0.5Gi</p></td><td><p>0.1</p></td><td><p>0.5Gi</p></td></tr><tr><td><p>Gateway</p></td><td><p>2</p></td><td><p>0.5</p></td><td><p>3Gi</p></td><td><p>1</p></td><td><p>6Gi</p></td></tr><tr><td><p>NextGen
    UI</p></td><td><p>2</p></td><td><p>0.2</p></td><td><p>0.2Gi</p></td><td><p>0.4</p></td><td><p>0.4Gi</p></td></tr><tr><td><p>Platform
    service</p></td><td><p>2</p></td><td><p>1</p></td><td><p>3Gi</p></td><td><p>2</p></td><td><p>6Gi</p></td></tr><tr><td><p>Test
    Intelligence</p></td><td><p>2</p></td><td><p>1</p></td><td><p>3Gi</p></td><td><p>2</p></td><td><p>6Gi</p></td></tr><tr><td><p>Access
    Control</p></td><td><p>2</p></td><td><p>1</p></td><td><p>3Gi</p></td><td><p>2</p></td><td><p>6Gi</p></td></tr><tr><td><p>CI
    Manager</p></td><td><p>2</p></td><td><p>1</p></td><td><p>3Gi</p></td><td><p>2</p></td><td><p>6Gi</p></td></tr><tr><td><p>NextGen
    Manager</p></td><td><p>2</p></td><td><p>2</p></td><td><p>6Gi</p></td><td><p>4</p></td><td><p>12Gi</p></td></tr><tr><td><p>Pipeline</p></td><td><p>2</p></td><td><p>1</p></td><td><p>6Gi</p></td><td><p>2</p></td><td><p>12Gi</p></td></tr><tr><td><p><strong>Total</strong></p></td><td><p>
    <strong>19</strong></p></td><td><p></p></td><td><p><strong> </strong></p></td><td><p><strong>17.5</strong></p></td><td><p><strong>61.9Gi</strong></p></td></tr></tbody></table><h3>Development
    Environment</h3><p>The following table lists the requirements for the installation
    of Self-Managed Enterprise Edition in the development environment.</p><table><tbody><tr><td><p><strong>Microservice</strong></p></td><td><p><strong>Pods</strong></p></td><td><p><strong>CPU
    / Pod</strong></p></td><td><p><strong>Memory / Pod</strong></p></td><td><p><strong>Total
    CPU</strong></p></td><td><p><strong>Total Memory</strong></p></td></tr><tr><td><p>Manager</p></td><td><p>1</p></td><td><p>2</p></td><td><p>4</p></td><td><p>2</p></td><td><p>4</p></td></tr><tr><td><p>Verification</p></td><td><p>1</p></td><td><p>1</p></td><td><p>3</p></td><td><p>1</p></td><td><p>3</p></td></tr><tr><td><p>Machine
    Learning Engine</p></td><td><p>1</p></td><td><p>3</p></td><td><p>2</p></td><td><p>3</p></td><td><p>2</p></td></tr><tr><td><p>UI</p></td><td><p>1</p></td><td><p>0.25</p></td><td><p>0.25</p></td><td><p>0.25</p></td><td><p>0.25</p></td></tr><tr><td><p>MongoDB</p></td><td><p>3</p></td><td><p>2</p></td><td><p>4</p></td><td><p>6</p></td><td><p>12</p></td></tr><tr><td><p>Proxy</p></td><td><p>1</p></td><td><p>0.5</p></td><td><p>0.5</p></td><td><p>0.5</p></td><td><p>0.5</p></td></tr><tr><td><p>Ingress</p></td><td><p>1</p></td><td><p>0.25</p></td><td><p>0.25</p></td><td><p>0.25</p></td><td><p>0.25</p></td></tr><tr><td><p>TimescaleDB</p></td><td><p>1</p></td><td><p>2</p></td><td><p>8</p></td><td><p>2</p></td><td><p>8</p></td></tr><tr><td><p>Kots
    Admin Pods</p></td><td><p> </p></td><td><p> </p></td><td><p> </p></td><td><p>4</p></td><td><p>8</p></td></tr><tr><td><p><strong>Total</strong></p></td><td><p><strong> </strong></p></td><td><p><strong> </strong></p></td><td><p><strong> </strong></p></td><td><p><strong>19</strong></p></td><td><p><strong>38</strong></p></td></tr></tbody></table><p></p><h3>Recommended
    Node Specifications</h3><p>Harness recommends the following minimum requirements
    for nodes.</p><ul><li>8 cores vCPU</li><li>12 GB memory</li></ul><h3>Storage Requirements</h3><p>Your
    Kubernetes cluster must attach a Kubernetes <a href="https://kubernetes.io/docs/reference/kubernetes-api/config-and-storage-resources/storage-class-v1/">StorageClass</a>
    resource. You provide the name of the <a href="https://kubernetes.io/docs/reference/kubernetes-api/config-and-storage-resources/storage-class-v1/">StorageClass</a>
    during the installation process.</p><p>A typical installation of Self-Managed
    Enterprise Edition uses a total of 1000 GB of storage in the following distribution:</p><table><tbody><tr><td><p><strong>Component</strong></p></td><td><p><strong>Pods</strong></p></td><td><p><strong>Storage
    per pod</strong></p></td><td><p><strong>Total</strong></p></td></tr><tr><td><p><strong>MongoDB</strong></p></td><td><p>3</p></td><td><p>200
    GB</p></td><td><p>600 GB</p></td></tr><tr><td><p><strong>Timescale DB</strong></p></td><td><p>3</p></td><td><p>120
    GB</p></td><td><p>360 GB</p></td></tr><tr><td><p><strong>Redis</strong></p></td><td><p>n/a</p></td><td><p>n/a</p></td><td><p>40
    GB</p></td></tr></tbody></table><p></p><p>A Proof of Concept (PoC) installation
    of Self-Managed Enterprise Edition requires 200 GB of storage in the following
    distribution:</p><table><tbody><tr><td><p><strong>Component</strong></p></td><td><p><strong>Pods</strong></p></td><td><p><strong>Storage
    per pod</strong></p></td><td><p><strong>Total</strong></p></td></tr><tr><td><p><strong>MongoDB</strong></p></td><td><p>3</p></td><td><p>50
    GB</p></td><td><p>150 GB</p></td></tr><tr><td><p><strong>Timescale DB</strong></p></td><td><p>1</p></td><td><p>20
    GB</p></td><td><p>20 GB</p></td></tr><tr><td><p><strong>Redis</strong></p></td><td><p>n/a</p></td><td><p>n/a</p></td><td><p>30
    GB</p></td></tr></tbody></table><p></p><h3>Allow List and Outbound Access Requirements</h3><p>Add
    the following URLs to your allow list:</p><table><tbody><tr><td><p><strong>URL</strong></p></td><td><p><strong>Usage</strong></p></td></tr><tr><td><p><strong>kots.io</strong></p></td><td><p>KOTS
    pulls the latest versions of the <code>kubectl</code> plugin and KOTS admin console
    (<code>kotsadm</code>).</p></td></tr><tr><td><p><strong>app.replicated.com </strong></p></td><td><p>KOTS
    admin console connects to check for the releases that your license allows.</p></td></tr><tr><td><p><strong>proxy.replicated.com</strong></p></td><td><p>Allows
    you to proxy your registry to pull your private images.</p></td></tr></tbody></table><p></p><p>Provide
    outbound access to the following URLs:</p><ul><li>proxy.replicated.com​</li><li>replicated.app</li><li>k8s.kurl.sh​</li><li>app.replicated.com</li></ul><div
    class="note-callout">Outbound access is required for <strong>connected install
    only</strong>. Outbound access is not required to install in <a href="https://kots.io/kotsadm/installing/airgap-packages/"
    target="_blank">Airgap mode</a>.</div><p>If your cluster does not have direct
    outbound connectivity and requires a proxy for outbound connections, see the following
    for information on how to create a proxy on the node machines: <a href="https://docs.docker.com/network/proxy/">https://docs.docker.com/network/proxy</a>.</p><h3>Cluster
    and Network Architecture</h3><p>The following diagram describes the cluster and
    network architecture for a Self-Managed Enterprise Edition Kubernetes Cluster
    installation.</p><p></p><figure><img src="https://files.helpdocs.io/i5nl071jo5/articles/d5lptkp5ow/1650670581995/clean-shot-2022-04-22-at-16-36-11-2-x.png"
    style="max-height:60%;max-width:60%" data-hd-height="60%" data-hd-width="60%"/></figure><p></p><h3>Namespace
    Requirements</h3><p>The examples in this documentation use the <code>harness</code>
    namespace.</p><p>If your installation will operate in a different namespace, you
    must update the Harness <code>spec</code> samples you use to apply the namespace
    you specified.</p><h3>Load Balancer</h3><p>The installation of Harness Self-Managed
    Enterprise Edition requires a load balancer. You enter the URL of the load balancer
    into the KOTS admin console when Self-Managed Enterprise Edition is installed.
    </p><p>After Harness Self-Managed Enterprise Edition is installed, the load balancer
    is used to access the Harness Manager UI with a web browser.</p><p>For information
    on how to create the load balancer, see <a href="/article/95mwydgm6w-kubernetes-cluster-on-prem-kubernetes-cluster-setup">Self-Managed
    Enterprise Edition - Kubernetes Cluster: Setup Guide</a>.</p><h4>gRPC and Load
    Balancer Settings</h4><p>The configuration of gRPC depends on load balancer support
    for HTTP2.</p><p><strong>Load balancer support for HTTP2 over port 443</strong></p><p>If
    your load balancer supports HTTP2 over port 443, you configure gRPC when you install
    Self-Managed Enterprise Edition NextGen. gRPC is configured in the <strong>GRPC
    Target</strong> and <strong>GRPC Authority</strong> fields.</p><figure><img src="https://files.helpdocs.io/i5nl071jo5/articles/d5lptkp5ow/1625082872413/clean-shot-2021-06-30-at-12-54-18.png"/></figure><p>The
    following table describes the <strong>GRPC Target</strong> and <strong>GRPC Authority</strong>
    fields. </p><table><tbody><tr><td><p><strong>Value</strong></p></td><td><p><strong>Description</strong></p></td></tr><tr><td><p><strong>GRPC
    Target</strong></p></td><td><p>The hostname of the load balancer. This is the
    URL of the load balancer.</p></td></tr><tr><td><p><strong>GRPC Authority</strong></p></td><td><p>Append
    the hostname to the following string:  <code>manager-grpc-&lt;hostname&gt;</code>.
    For example, <code>manager-grpc-35.202.197.230</code>.</p></td></tr></tbody></table><p></p><p><strong>No
    load balancer support for HTTP2 over port 443</strong></p><p>If your load balancer
    does not support HTTP2 over port 443, use one of the following configuration options:</p><ul><li><strong>Load
    balancer supports multiple SSL ports. </strong>Add port 9879 in the application
    load balancer and target port 9879 or node port 32510 on the Ingress controller.</li></ul><table><tbody><tr><td><p><strong>Value</strong></p></td><td><p><strong>Description</strong></p></td></tr><tr><td><p><strong>GRPC
    Target</strong></p></td><td><p>The hostname of the load balancer.</p></td></tr><tr><td><p><strong>GRPC
    Authority</strong></p></td><td><p>The hostname of the load balancer.</p><p></p></td></tr></tbody></table><ul><li><strong>Load
    balancer does not support multiple SSL ports. </strong>Create a new load balancer
    and target port 9879 or node port 32510 on the Ingress controller:</li></ul><table><tbody><tr><td><p><strong>Value</strong></p></td><td><p><strong>Description</strong></p></td></tr><tr><td><p><strong>GRPC
    Target</strong></p></td><td><p>The hostname of the new load balancer.</p></td></tr><tr><td><p><strong>GRPC
    Authority</strong></p></td><td><p>The hostname of the new load balancer.</p></td></tr></tbody></table><h3>Trusted
    Certificate Requirement for Harness Self-Managed Enterprise Edition</h3><p>You
    can use secure or unencrypted connections to Harness Manager. This option depends
    on the URL scheme you apply during installation, when you configure the <strong>Load
    Balancer URL</strong> field. You can use <code>https://</code> or <code>http://</code>.</p><figure><img
    src="https://files.helpdocs.io/kw8ldg1itf/articles/v6x4n5j9lv/1604688719498/image.png"
    style="max-height:50%;max-width:50%" data-hd-height="50%" data-hd-width="50%"/></figure><p>For
    secure connections from your integrations to Harness Manager, you must use a public
    trusted certificate. This includes your integration with Harness Delegate as well
    as to Github Webhooks and so on.  Harness does not support self-signed certificates
    for connections to  Harness Manager.</p><p>For connections from Harness Manager
    outbound to an integration, you can use a self-signed certificate. In this case,
    you must import the self-signed certificate into Harness Delegate&#39;s JRE keystore
    manually or by using a Harness Delegate Profile.</p><h4>Terminate at Harness</h4><p>You
    have the option to terminate at the Harness ingress instead of the load balancer.
    If you configured the Harness ingress controller, you can add a TLS secret to
    the <code>harness</code> namespace.</p><p>The following instruction adds a TLS
    secret based on a public certificate with the name <code>harness-cert</code>:</p><pre>kubectl
    create secret tls harness-cert --cert=path/to/cert/file --key=path/to/key/file</pre><p></p><p></p><p></p><p></p><p></p><p></p>'
  slug: kubernetes-cluster-on-prem-infrastructure-requirements
  tags:
  - on-premises
  is_live: true
