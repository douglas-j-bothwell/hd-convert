type: article
article_id: dvl3hzjuhw
user_id: mfr0nxh4be
category_id: gul20j54zg
author:
  name: Michael Cretzman
  profile_image: https://www.gravatar.com/avatar/2e8616837f4ee92be5d19ffe9b9ccba9?d=mm&s=150
title: Connected On-Prem Backup and Restore Strategy
slug: harness-docker-connected-on-prem-backup-strategy
description: Backup and restore strategies for the Harness On-Prem MongoDB database.
short_version: Backup strategies for the Harness On-Prem MongoDB database.
tags:
- on-premise
- MongoDB
- Mongodump
- Mongorestore
show_toc: true
is_private: false
is_published: false
is_featured: false
stale_status:
  is_stale: false
  reason: ""
  source: API
  triggered_at: 2022-04-25T20:42:46.462763Z
  expires_at: null
permission_groups: []
multilingual:
- language_code: en
  title: Connected On-Prem Backup and Restore Strategy
  description: Backup and restore strategies for the Harness On-Prem MongoDB database.
  short_version: Backup strategies for the Harness On-Prem MongoDB database.
  body: '<p>Database backups are extremely important to protect Production Database
    data and prevent data loss. Harness On-Prem uses MongoDB and TimeScaleDB as its
    databases. This topic describes how to perform the necessary backups of Harness
    databases and ensure you are prepared for disaster recovery.</p><p>In this topic:</p><ul><li><a
    href="#harness_backup_strategy_overview">Harness Backup Strategy Overview</a></li><li><a
    href="#full_backup_method">Full Backup Method</a><ul><li><a href="#full_backup_process_for_3_box_docker_connected_on_prem_setup">Full
    Backup Process for 3-box Docker Connected On-Prem Setup</a></li><li><a href="#restore_process">Restore
    Process</a></li></ul></li></ul><h3>Harness Backup Strategy Overview</h3><p>This
    section describes Harness&#39; recommended backup strategy. The strategy proposed
    below provides two layers of protection.</p><p>Please schedule all of the following
    below backup methods to protect Harness On-Prem System from data loss:</p><ul><li><strong>Harness
    GitSync</strong> — Please use <a href="/article/htvzryeqjw-configuration-as-code">Harness
    GitSync</a> to ensure all Harness entities (including configurations) are backed
    up incase of database loss. </li><li><strong>Full Backup Method</strong> — Daily
    full database backups using crontab.</li></ul><div class="warning-callout">Please
    test backup commands before using them in Production.</div><h3>Full Backup Method</h3><p>Harness
    recommends you perform full backups every 6 hours (or at a frequency you prefer)
    using the method given below.</p><h4>Full Backup Process for 3-box Docker Connected
    On-Prem Setup</h4><ol><li>Select the node where TimeScaleDB is running.<ol><li>You
    can verify this by running <code>docker ps</code> on the node and verifying that
    <code>harness-timescaledb</code> is running on the node. You can also check with
    Harness to verify the node.</li></ol></li><li>Derive the <strong>MONGO_URI</strong>
    from the Harness Manager by running the following command on the node: <br/> <br/><code>docker
    inspect harnessManager | grep MONGO_URI</code></li><li>Populate the value of <strong>MONGO_URI</strong>
    in the script below and save the script on the node as <strong>harness_dump.sh</strong>.</li></ol><pre>#!/usr/bin/env
    bash<br/><br/>set -e<br/>set -x<br/><br/>MONGO_URI=&#34;&lt;MONGO_URI&gt;&#34;<br/><br/>destination=${1:-.}<br/>current_date=$(date
    &#34;+%Y.%m.%d-%H.%M.%S&#34;)<br/><br/><br/>mkdir -p $destination/$current_date/timescale<br/>docker
    exec -i harness-timescaledb psql -U admin -d harness -c &#34;\COPY (SELECT * FROM
    instance_stats) TO /var/lib/postgresql/data/instance_stats.csv DELIMITER &#39;,&#39;
    CSV&#34;<br/>docker exec -i harness-timescaledb psql -U admin -d harness -c &#34;\COPY
    (SELECT * FROM deployment) TO /var/lib/postgresql/data/deployment.csv DELIMITER
    &#39;,&#39; CSV&#34;<br/>docker cp harness-timescaledb:/var/lib/postgresql/data/instance_stats.csv
    $destination/$current_date/timescale<br/>docker cp harness-timescaledb:/var/lib/postgresql/data/deployment.csv
    $destination/$current_date/timescale<br/>cd $destination/$current_date/ &amp;&amp;
    tar -cvzf timescale.tar timescale &amp;&amp; cd -<br/>rm -rf $destination/$current_date/timescale<br/><br/><br/>#Get
    mongoDB dump<br/><br/>mongo_uri=$(echo ${MONGO_URI} | sed &#39;s/\\//g&#39;)<br/><br/>mkdir
    -p $destination/$current_date<br/>docker exec -i mongoContainer mongodump --uri=&#34;${mongo_uri}&#34;
    --out /data/db/backup/dump<br/>docker cp -a mongoContainer:/data/db/backup/dump
    $destination/$current_date<br/>cd $destination/$current_date/ &amp;&amp; tar -cvzf
    mongo.tar dump &amp;&amp; cd -<br/>rm -rf $destination/$current_date/dump</pre><p>The
    above script takes one optional argument: The backup folder where the files should
    be stored.If you do not provide the value, the default is the current directory
    where you are running the script.</p><ol><li start="4" style="counter-increment:li
    3">Test the script is working correctly by running the script as bash harness_dump.sh.<br/>
    <br/>If the script has worked successfully, then you should see a folder created
    at the current directory location with a name corresponding to the timestamp.
    For example:<strong> 2020.03.18-07.18.32</strong>.<br/> <br/>Inside the folder,
    there should be two TARs: mongo.tar and timescale.tar. Here is an example:</li></ol><pre>~/2020.03.18-07.18.32$
    ls -l<br/><br/>total 76884<br/><br/>-rw-rw-r-- 1 demo demo 78715723 Mar 18 07:18
    mongo.tar<br/><br/>-rw-rw-r-- 1 demo demo     5031 Mar 18 07:18 timescale.tar</pre><p></p><ol><li
    start="5" style="counter-increment:li 4">Set up a cron job for this script to
    be run every 6 hours (or at a frequency you prefer). <br/> <br/>Ensure you pass
    in the directory where the backups will be stored as an argument to the script.
    For example:</li></ol><pre>0 */6 * * * bash /home/harness.svc.account.user/harness_dump.sh
    /home/harness.svc.account.user/backup &gt; /home/harness.svc.account.user/backup/output.log
    2&gt;&amp;1</pre><ol><li start="6" style="counter-increment:li 5">Ensure that
    the backup directory has enough space for storing the backups. You can setup a
    cron job for deleting files older than a fixed duration to clean up old backups.<br/>
    <br/>For example, this cron job runs once a day at 1am and deletes files older
    than 30 days. This prevents the backup directory from filling up.</li></ol><pre>0
    1 * * * find /home/harness.svc.account.user/backup/* -mtime +30 -exec rm -rf {}
    \; &gt;&gt; /home/harness.svc.account.user/backlog_folder/cleanup.log 2&gt;&amp;1</pre><div
    class="warning-callout"><strong>Important</strong> — Please ensure you perform
    the following:</div><p></p><ol><li start="7" style="counter-increment:li 6">The
    backup folder should be copied into a redundant storage regularly. The storage
    should be available in case of a DC failure so it can be restored on another DC.</li><li>The
    above script will only work if the TimeScaleDB and MongoDB containers are running
    on the node.<br/><br/>If the containers are down, please bring them back up. This
    prevents the backups from failing.</li><li>Please utilize the <a href="/article/wd8ltzh855-on-prem-monitoring">Harness
    Monitoring Service</a> to ensure that the services are running on the system.</li></ol><h4>Restore
    Process</h4><p>Perform the following steps below on the target cluster. </p><ol><li>Please
    copy the backup you are restoring to the target cluster node where TimeScaleDB
    is running.  You can check with Harness to verify the node.</li><li>Ensure TimeScaleDB
    and MongoDB are running on the node:<br/> <br/><code>docker inspect harnessManager</code><br/><code>docker
    inspect harness-timescaledb</code></li><li>Ensure all MongoDB nodes are running
    on all 3 nodes using the <a href="https://docs.harness.io/article/wd8ltzh855-on-prem-monitoring">Harness
    Monitoring</a> dashboard. <ol><li>Run <code>docker ps</code> on each node to verify
    that <code>mongoContainer</code> is running.</li></ol></li><li>Derive the <strong>MONGO_URI</strong>
    from the Harness Manager by running the following command on the node:<br/> <br/><code>docker
    inspect harnessManager | grep MONGO_URI</code></li><li>Stop the Harness Manager
    and Harness Verification service on all 3 nodes by running the following on all
    3 nodes: <br/> <br/><code>docker kill harnessManager verificationService</code><br/>You
    can run docker ps on each node to see if harnessManager and verificationService
    are not running.</li><li>Populate the value of <code>&lt;MONGO_URI&gt;</code>
    in the script below and save it as harness_restore.sh:</li></ol><pre>#!/usr/bin/env
    bash<br/>set -e<br/>set -x<br/>if [[ -z &#34;${1}&#34; ]]; then<br/>  echo &#34;Target
    directory not specified, please pass in a target directory argument&#34;<br/>  exit
    1<br/>fi<br/>MONGO_URI=&#34;&lt;MONGO_URI&gt;&#34;<br/>source=$1<br/>cd $source
    &amp;&amp; tar -xvf timescale.tar &amp;&amp; cd -<br/>docker cp $source/timescale/instance_stats.csv
    harness-timescaledb:/var/lib/postgresql/data/instance_stats.csv<br/>docker cp
    $source/timescale/deployment.csv harness-timescaledb:/var/lib/postgresql/data/deployment.csv<br/>docker
    exec -it harness-timescaledb psql -U admin -d harness -c &#34;DELETE FROM instance_stats;&#34;<br/>docker
    exec -it harness-timescaledb psql -U admin -d harness -c &#34;DELETE FROM deployment;&#34;<br/>docker
    exec -it harness-timescaledb psql -U admin -d harness -c &#34;\COPY instance_stats
    FROM /var/lib/postgresql/data/instance_stats.csv CSV&#34;<br/>docker exec -it
    harness-timescaledb psql -U admin -d harness -c &#34;\COPY deployment FROM /var/lib/postgresql/data/deployment.csv
    CSV&#34;<br/>mongo_uri=$(echo ${MONGO_URI} | sed &#39;s/\\//g&#39;)<br/>cd $source
    &amp;&amp; tar -xvf mongo.tar &amp;&amp; cd -<br/>echo &#34;use harness&#34; &gt;
    drop_harness.sh<br/>echo &#34;db.dropDatabase();&#34; &gt;&gt; drop_harness.sh<br/>echo
    mongo_uri=&#34;$mongo_uri&#34;<br/>docker cp drop_harness.sh mongoContainer:/data/db/<br/>docker
    cp  $source/dump mongoContainer:/data/db/<br/>docker exec -it mongoContainer bash
    -c &#34;mongo \&#34;${mongo_uri}\&#34; &lt; /data/db/drop_harness.sh&#34;<br/>docker
    exec -it mongoContainer mongorestore --uri=&#34;${mongo_uri}&#34; --drop /data/db/dump<br/>rm
    drop_harness.sh</pre><p></p><ol><li start="7" style="counter-increment:li 6">The
    above script takes one argument: the location of the backup.<br/><br/>For example,
    if you copied the backup <code>2020.03.18-19.00.01</code> to the current directory,
    you can execute the script as <code>bash harness_restore.sh 2020.03.18-19.00.01</code>.</li><li>Check
    the health of the MongoDB replicaset by running the following command. Replace
    <code>&lt;MONGO_URI&gt;</code> in the value below:<br/> <br/><code>docker exec
    -i mongoContainer mongo “&lt;MONGO_URI&gt;” --eval=&#34;rs.status();”</code></li><li>Use
    the local <a href="/article/prry6nu01y-docker-connected-start-stop">start and
    stop scripts</a> on the Ambassador to restore the system back to its healthy state.</li><li>Reconfigure
    the Load Balancer to point to the nodes on the target cluster.</li></ol><p></p><p></p><p></p><p></p>'
  slug: harness-docker-connected-on-prem-backup-strategy
  tags:
  - on-premise
  - MongoDB
  - Mongodump
  - Mongorestore
  is_live: true
