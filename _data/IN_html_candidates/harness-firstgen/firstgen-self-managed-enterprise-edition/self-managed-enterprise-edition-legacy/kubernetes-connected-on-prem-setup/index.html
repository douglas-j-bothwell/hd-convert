<p>In addition to the Harness SaaS offering, you can run the Harness Continuous Delivery-as-a-Service platform on-premise, in a local Kubernetes cluster.</p>
<p>For more information, see the Harness Blog article:
  <a href="https://harness.io/2019/03/harness-uses-kubernetes-for-on-premises-deployment/">Harness uses Kubernetes for On-Premises Deployment</a>.</p>
<p>This topic contains the following sections:</p>
<ul>
  <li>
    <a href="#pre_installation">Pre-Installation</a>
    <ul>
      <li>
        <a href="#architecture">Architecture</a>
      </li>
      <li>
        <a href="#on_prem_requirements">On-Prem Requirements</a>
      </li>
    </ul>
  </li>
  <li>
    <a href="#trusted_certificate_requirement_for_harness_on_prem">Trusted Certificate Requirement for Harness On-Prem</a>
  </li>
  <li>
    <a href="#installation">Installation</a>
    <ul>
      <li>
        <a href="#docker_repo_setup">Docker Repo Setup</a>
      </li>
      <li>
        <a href="#kubernetes_cluster_and_namespace_setup">Kubernetes Cluster and Namespace Setup</a>
      </li>
      <li>
        <a href="#kubernetes_config_file_setup">Kubernetes Config File Setup</a>
      </li>
      <li>
        <a href="#docker_repo_secret_setup">Docker Repo Secret Setup</a>
      </li>
      <li>
        <a href="#option_store_certificate_secret_in_harness_namespace">Option: Store Certificate Secret in Harness Namespace</a>
      </li>
      <li>
        <a href="#ambassador_virtual_machine_setup">Ambassador Virtual Machine Setup</a>
      </li>
      <li>
        <a href="#load_balancer_setup">Load Balancer Setup</a>
      </li>
      <li>
        <a href="#avoid_common_issues">Avoid Common Issues</a>
      </li>
      <li>
        <a href="#send_information_to_harness">Send Information to Harness</a>
      </li>
      <li>
        <a href="#install_harness">Install Harness</a>
      </li>
    </ul>
  </li>
  <li>
    <a href="#post_installation">Post-Installation</a>
  </li>
  <li>
    <a href="#important_next_steps">Important Next Steps</a>
  </li>
  <li>
    <a href="#notes">Notes</a>
  </li>
</ul>
<h3>Pre-Installation</h3>
<p>This section describes the Kubernetes On-Prem architecture and the requirements for all its components.</p>
<p>The next section,
  <a href="#installation">Installation</a>, describes how to set up and test each component.</p>
<h4>Architecture</h4>
<p>Here is the high-level architecture of the installed Harness Connected On-Prem with Kubernetes:</p>
<p></p>
<figure>
  <img src="https://files.helpdocs.io/kw8ldg1itf/articles/go5nk41qvd/1589218612419/image.png"/>
</figure>
<p>The main components are:</p>
<ol>
  <li>Kubernetes cluster hosting the Harness microservices for On-Prem.</li>
  <li>Docker repository hosting the Harness microservice images that will be pulled by the cluster.</li>
  <li>Harness Ambassador hosted on a Virtual Machine (VM). The Ambassador does the following:
    <ol>
      <li>Makes a secure outbound connection to the Harness Cloud to download binaries and container images.</li>
      <li>Push container images to your Docker repository using Docker client.</li>
      <li>Installs images into the Kubernetes cluster using kubectl.</li>
    </ol>
  </li>
  <li>Load Balancer that connects to the static node port of the Ingress controller in the Harness namespace (other options are discussed in
    <a href="#load_balancer_setup">Load Balancer Setup</a>). You provide Harness with the internal URL used by the LB.</li>
  <li>Harness Cloud from where the Ambassador downloads the binaries and container images.</li>
</ol>
<p>The steps in this document are simply the process of setting up and testing each component and then installing Harness On-Prem.</p>
<p>Let&#39;s get started by reviewing the requirements for the components.</p>
<h4>On-Prem Requirements</h4>
<p>This section lists the infrastructure requirements that must be in place before following the installation steps later in this document.</p>
<h5>Kubernetes Cluster Requirements</h5>
<p>The Kubernetes cluster must meet the following:</p>
<ul>
  <li>Kubernetes cluster (v1.9 to 1.15.x) with a dedicated namespace: <strong>harness</strong>.
    <br/>Instructions for the creating the namespace are below in
    <a href="#kubernetes_cluster_and_namespace_setup">Kubernetes Cluster and Namespace Setup</a>.</li>
  <li>33.5 cores, 67.5 GB RAM, 910 GB disk storage (see table and storage volume list below).</li>
</ul>
<p></p>
<table>
  <tbody>
    <tr>
      <td>
        <p><strong>Microservice</strong></p>
      </td>
      <td>
        <p><strong>Pods</strong></p>
      </td>
      <td>
        <p><strong>CPU</strong></p>
      </td>
      <td>
        <p><strong>Memory (GB)</strong></p>
      </td>
    </tr>
    <tr>
      <td>
        <p>Manager</p>
      </td>
      <td>
        <p>2</p>
      </td>
      <td>
        <p>4</p>
      </td>
      <td>
        <p>10</p>
      </td>
    </tr>
    <tr>
      <td>
        <p>Verification</p>
      </td>
      <td>
        <p>2</p>
      </td>
      <td>
        <p>2</p>
      </td>
      <td>
        <p>6</p>
      </td>
    </tr>
    <tr>
      <td>
        <p>Machine Learning Engine</p>
      </td>
      <td>
        <p>1</p>
      </td>
      <td>
        <p>8</p>
      </td>
      <td>
        <p>2</p>
      </td>
    </tr>
    <tr>
      <td>
        <p>UI</p>
      </td>
      <td>
        <p>2</p>
      </td>
      <td>
        <p>0.5</p>
      </td>
      <td>
        <p>0.5</p>
      </td>
    </tr>
    <tr>
      <td>
        <p>MongoDB</p>
      </td>
      <td>
        <p>3</p>
      </td>
      <td>
        <p>12</p>
      </td>
      <td>
        <p>24</p>
      </td>
    </tr>
    <tr>
      <td>
        <p>Proxy</p>
      </td>
      <td>
        <p>1</p>
      </td>
      <td>
        <p>0.5</p>
      </td>
      <td>
        <p>0.5</p>
      </td>
    </tr>
    <tr>
      <td>
        <p>Ingress</p>
      </td>
      <td>
        <p>2</p>
      </td>
      <td>
        <p>0.5</p>
      </td>
      <td>
        <p>0.5</p>
      </td>
    </tr>
    <tr>
      <td>
        <p>TimescaleDB</p>
      </td>
      <td>
        <p>3</p>
      </td>
      <td>
        <p>6</p>
      </td>
      <td>
        <p>24</p>
      </td>
    </tr>
    <tr>
      <td>
        <p>Total</p>
      </td>
      <td>
        <p>16</p>
      </td>
      <td>
        <p>33.5</p>
      </td>
      <td>
        <p>67.5</p>
      </td>
    </tr>
  </tbody>
</table>
<ul>
  <li>Storage volume (200 GB) for each Mongo pod (600 GB total).</li>
  <li>Storage volume (100 GB) for each TimeScaleDB pod (300 GB total).</li>
  <li>Storage volume (10 GB) for the Proxy pod.</li>
</ul>
<h5>Docker Repository Server Requirements</h5>
<p>The server that will host the Docker repository must meet the following requirements. </p>
<div class="note-callout">The instructions for adding the requirements are described in
  <a href="#docker_repo_setup">Docker Repo Setup</a> and
  <a href="#ambassador_virtual_machine_setup">Ambassador Virtual Machine Setup</a>.</div>
<ul>
  <li><strong>Docker repository</strong> — Harness requires a Docker repo for the Harness microservice images that will be pulled by the Kubernetes cluster.</li>
  <li><strong>Docker user account</strong> — A Docker repo user account will be used by the Docker client on the Ambassador VM to access the Docker repo.
    <br/>
    <br/>It is also used to create a Kubernetes secret. This secret is used by the Ambassador when it runs kubectl commands remotely on the Kubernetes cluster and pulls images from the repo.</li>
  <li><strong>Important:</strong> The Docker repo user account should have permissions to read, write, and create new repositories on the Docker registry.</li>
</ul>
<p>If the user lacks the permission to create new repositories, contact Harness Support to pre-create the repositories for the installation.</p>
<h5>Harness Ambassador VM Requirements</h5>
<div class="note-callout">If you are using the Ambassador Docker images from Harness, they have all of the prerequisites.</div>
<p>The Harness Ambassador VM must meet the following requirements. Please install the required software.</p>
<div class="note-callout">The instructions for testing the software requirements are described in
  <a href="#ambassador_virtual_machine_setup">Ambassador Virtual Machine Setup</a>.</div>
<p></p>
<ul>
  <li><strong>System</strong> — 1 core, 6GB RAM, 20 GB Disk.</li>
  <li><strong>Connectivity to the Harness Cloud</strong> — The Ambassador VM must be able to connect to hostname <strong>app.harness.io and port 443</strong>. The following command will check connectivity to the Harness Cloud:
    <br/>
    <br/><code>nc -vz app.harness.io 443</code>
    <br/>
    <br/>
    <ul>
      <li><strong>Optional: Proxy file-size limit</strong> — If you have a proxy set up in front of the Ambassador to reach app.harness.io, ensure that your proxy&#39;s configuration allows downloads of files as large as 2 GB. This is required to pull the
        artifacts that the Ambassador will download to install and upgrade Harness microservices. On
        <a href="https://httpd.apache.org/docs/2.2/mod/core.html#limitrequestbody">Apache</a>, set this limit using <code>theLimitRequestBody</code> directive. On
        <a href="http://nginx.org/en/docs/http/ngx_http_core_module.html#client_max_body_size">nginx</a>, use the <code>client_max_body_size directive</code>.</li>
    </ul>
  </li>
  <li><strong>Docker</strong> —
    <a href="https://docs.docker.com/engine/install/">Install Docker</a> on the Ambassador VM. The Docker client is used to log the Ambassador into the Docker repository containing the Harness images.
    <br/>Also, follow the
    <a href="https://docs.docker.com/install/linux/linux-postinstall/">Docker post install steps</a>. Exit, log back on, and verify that you can run Docker using <code>docker ps</code>.</li>
  <li><strong>kubectl</strong> — The kubectl CLI must be installed on the Ambassador VM. kubectl is used to execute Kubernetes commands for the remote Kubernetes cluster <strong>harness</strong> namespace.
    <br/>Once you have created the Kubernetes cluster (described in
    <a href="#kubernetes_cluster_and_namespace_setup">Kubernetes Cluster and Namespace Setup</a>), you will create a kubeconfig file using a script and copy it to the Ambassador VM (as described in
    <a href="#kubernetes_config_file_setup">Kubernetes Config File Setup</a>). The kubeconfig file configures kubectl on the Ambassador VM to connect to the harness namespace in the remote Kubernetes cluster.</li>
  <li><strong>Linux user account</strong> — A dedicated user account used to run the Harness Ambassador. The user account does not need to have root access on localhost. It should have default user permissions.</li>
  <li><strong>cURL</strong></li>
  <li><strong>Unzip</strong></li>
  <li><strong>sed</strong></li>
</ul>
<div class="note-callout"><strong>Running a Container-based Ambassador</strong> — If you choose to run the Ambassador as a Docker image, root access on localhost is required. If root access is not possible, please follow the instructions on how to run Docker as a non-root user:
  <a href="https://docs.docker.com/install/linux/linux-postinstall/">https://docs.docker.com/install/linux/linux-postinstall/</a>.</div>
<p></p>
<h5>Networking and Access Requirements</h5>
<p>The following connections must be enabled:</p>
<ul>
  <li>Load balancer to Kubernetes cluster.</li>
  <li>The Kubernetes cluster needs network connectivity to the internal Docker repository to pull images.</li>
  <li>Ambassador to Kubernetes cluster to run kubectl commands.</li>
  <li>Ambassador to the Docker repository server to push Harness images.</li>
  <li>Ambassador to domain <strong>app.harness.io</strong> (port: <strong>443</strong>).</li>
</ul>
<h5>Load Balancer</h5>
<p>The type of load balancer you use to support Harness On-Prem is your decision.</p>
<p>Ensure that the load balancer you configure supports the networking requirements described earlier.</p>
<p>The instructions for configuring the load balancer are described in
  <a href="#load_balancer_setup">Load Balancer Setup</a>.</p>
<h3>Trusted Certificate Requirement for Harness On-Prem</h3>
<p>All connections to the Harness Manager can be secure or unencrypted according to the URL scheme you use (<code>https://</code> or <code>http://</code>).</p>
<p>For secure connections from any integration into the Harness Manager (Github Webhooks, etc), including the <strong>Harness Delegate</strong>, you must use a
  <u>publicly trusted certificate</u>.</p>
<p>Harness does not support self-signed certificates for connections to the Harness Manager.</p>
<p>For connections from the Harness Manager outbound to an integration, you can use a self-signed certificate. In this case, you must import the self-signed certificate into Harness Delegate&#39;s JRE keystore manually or using a Harness
  <a href="https://docs.harness.io/article/yd4bs0pltf-run-scripts-on-the-delegate-using-profiles">Delegate Profile</a>.</p>
<p>See
  <a href="https://docs.harness.io/article/8bj3v5jqzk-add-self-signed-certificates-for-delegate-connections">Add Self-Signed Certificates for Delegate Connections</a>.</p>
<h3>Installation</h3>
<p>Once you have configured the requirements in
  <a href="#pre_installation">Pre-Installation</a>, use the instructions in this section to set up each of the Harness Kubernetes On-Prem components.</p>
<p>The instructions are organized so you don&#39;t have to jump back and forth between servers.</p>
<h4>Docker Repo Setup</h4>
<p>As described in
  <a href="#architecture">Architecture</a>, the Harness microservice images downloaded by the Ambassador are kept in a Docker repository in your environment.</p>
<p></p>
<figure>
  <img src="https://files.helpdocs.io/kw8ldg1itf/articles/go5nk41qvd/1589220999745/image.png"/>
</figure>
<p>This step describes how to set up the Docker repository for Harness On-Prem.</p>
<ol>
  <li>Create a Docker repository using standard Docker setup commands as described in Docker&#39;s
    <a href="https://docs.docker.com/ee/dtr/user/manage-images/">documentation</a>.</li>
</ol>
<div class="note-callout"><strong>Important —</strong> Record the Docker repository&#39;s <strong>internal URL</strong>. You will send this URL to Harness later, as well as use it to configure the Docker repo secret used by Harness microservices. </div>
<ol>
  <li style="counter-increment:li 1" start="2">Next, create a Docker user for the Ambassador. Later, when you set up the Ambassador VM, you run <code>docker login</code> to log in as this user from the Ambassador.
    <br/>This command will cache the credentials on the Ambassador to use them for future connections.</li>
</ol>
<p>The preceding steps are for generic Docker setup; however, you might be running Docker on a cloud platform. Please consult the cloud platform documentation for setting up Docker to meet the requirements stated above.</p>
<p>As an example of a cloud platform Docker setup, the next section shows the Docker setup for Google Container Registry (GCR).</p>
<h5>Google Container Registry (GCR) Example</h5>
<p>Here is an example of authenticating into Google Container Registry (GCR), adding its Docker credentials, and then verifying the Docker repo:</p><pre>$ gcloud auth login<br/> <br/>Response:<br/> <br/>Your browser has been opened to visit:<br/>    https://accounts.google.com/o/oauth2/auth?...<br/><br/>You are now logged in as [jane.doe@harness.io].<br/>Your current project is [qa-setup].  You can change this setting by running:<br/> <br/>$ gcloud config set project PROJECT_ID<br/> <br/>janedoe@jane-doe ~ % gcloud config set project playground-123<br/>Updated property [core/project].<br/><br/><br/>janedoe@jane-doe ~ % gcloud auth configure-docker<br/><br/><br/>Adding credentials for all GCR repositories.<br/><br/><br/>WARNING: A long list of credential helpers may cause delays running &#39;docker build&#39;. We recommend passing the registry name to configure only the registry you are using.<br/>After update, the following will be written to your Docker config file<br/> located at [/Users/janedoe/.docker/config.json]:<br/> {<br/>  &#34;credHelpers&#34;: {<br/>    &#34;gcr.io&#34;: &#34;gcloud&#34;, <br/>    &#34;marketplace.gcr.io&#34;: &#34;gcloud&#34;, <br/>    &#34;eu.gcr.io&#34;: &#34;gcloud&#34;, <br/>    &#34;us.gcr.io&#34;: &#34;gcloud&#34;, <br/>    &#34;staging-k8s.gcr.io&#34;: &#34;gcloud&#34;, <br/>    &#34;asia.gcr.io&#34;: &#34;gcloud&#34;<br/>  }<br/>}<br/> <br/>Do you want to continue (Y/n)?  y<br/> <br/>Docker configuration file updated.<br/> <br/>docker pull busybox<br/>Using default tag: latest<br/>latest: Pulling from library/busybox<br/>e2334dd9fee4: Pull complete <br/>Digest: sha256:a8cf7ff6367c2afa2a90acd081b484cbded349a7076e7bdf37a05279f276bc12<br/>Status: Downloaded newer image for busybox:latest<br/> <br/>docker tag busybox us.gcr.io/playground-123/jane-test/busybox:tag1<br/>docker push us.gcr.io/playground-123/jane-test/busybox<br/>The push refers to a repository [us.gcr.io/playground-123/jane-test/busybox]<br/>5b0d2d635df8: Pushed <br/>tag1: digest: sha256:de8c8ce88a54ec933a7a7d350c3a33e8cadadf2801c9129a879b4efeb93ed863 size: 527</pre>
<p></p>
<h4>Kubernetes Cluster and Namespace Setup</h4>
<p>This step describes how to set up your Kubernetes platform for Harness On-Prem.</p>
<p>When On-Prem is installed later, the Harness On-Prem microservices are pulled from the Docker repository you set up to the Kubernetes cluster where they will run.</p>
<p></p>
<figure>
  <img src="https://files.helpdocs.io/kw8ldg1itf/articles/go5nk41qvd/1589221910101/image.png"/>
</figure>
<p>In this step, we will use the Kubernetes YAML manifest file provided by Harness to create all necessary objects in Kubernetes for Harness, including:</p>
<ul>
  <li>A <strong>namespace</strong> named <strong>harness</strong>.</li>
  <li>A <strong>Service account</strong> named <strong>harness-namespace-admin</strong> with all permissions within the <strong>harness</strong> namespace.</li>
  <li>A <strong>Role</strong> called <strong>harness-namespace-admin-full-access</strong> that provides access to the required API groups (apiGroups).</li>
  <li>A <strong>RoleBinding</strong> called <strong>harness-namespace-admin-view</strong> that connects the service account and the role that provides access on the required API groups.</li>
</ul>
<p>Do the following:</p>
<ol>
  <li>Download the
    <a href="https://harness-onprem-resources-files.s3-us-west-1.amazonaws.com/harness-resources.yaml">harness-resources.yaml</a> from Harness.</li>
  <li>Log into your Kubernetes platform as a user with <strong>cluster admin credentials</strong>.</li>
  <li>Run harness-resources.yaml with the following command:
    <br/>
    <br/><code>kubectl apply -f harness-resources.yaml</code></li>
</ol>
<p>The output should look something like this:</p><pre>namespace/harness created<br/>serviceaccount/harness-namespace-admin created<br/>role.rbac.authorization.k8s.io/harness-namespace-admin-full-access created<br/>rolebinding.rbac.authorization.k8s.io/harness-namespace-admin-view created<br/>clusterrole.rbac.authorization.k8s.io/harness-clusterrole created<br/>serviceaccount/harness-serviceaccount created<br/>clusterrolebinding.rbac.authorization.k8s.io/harness-clusterrole-hsa-binding created</pre>
<p>Now that the <strong>harness</strong> namespace is created, we will create a secret in the namespace for the Ambassador to use later. The secret is stored in a kubeconfig file that you will copy to the Ambassador VM later.</p>
<p></p>
<h4>Kubernetes Config File Setup</h4>
<p>In this step, we create and test the kubeconfig file that the Ambassador will use later to access the Kubernetes namespace in the cluster you created.</p>
<p>Later, when you set up the Ambassador in
  <a href="#ambassador_virtual_machine_setup">Ambassador Virtual Machine Setup</a>, you will copy this kubeconfig file to the Ambassador VM. The Harness Ambassador will use this file to execute kubectl commands on the remote Kubernetes cluster:</p>
<p></p>
<figure>
  <img src="https://files.helpdocs.io/kw8ldg1itf/articles/go5nk41qvd/1589222350361/image.png"/>
</figure>
<div class="note-callout">Ensure you have the
  <a href="https://stedolan.github.io/jq/">jq command-line JSON processor</a> installed before you execute this script.</div>
<ol>
  <li>Download the
    <a href="https://harness-onprem-resources-files.s3-us-west-1.amazonaws.com/generate_kubeconfig.sh">generate_kubeconfig.sh</a> file from Harness (right-click and save the file).</li>
  <li>Run the <strong>generate_kubeconfig.sh</strong> file you downloaded:
    <br/>
    <br/><code>bash ./generate_kubeconfig.sh</code></li>
</ol>
<p>The output should look something like this example from GCP:</p><pre>Creating target directory to hold files in ./kube/...done<br/>Getting secret of service account harness-namespace-admin-harness<br/>Secret name: harness-namespace-admin-token-&lt;id&gt;<br/> <br/>Extracting ca.crt from secret...done<br/>Getting user token from secret...done<br/>Setting current context to: &lt;your_cluster_name&gt;<br/>Cluster name: &lt;your_cluster_name&gt;<br/> <br/>Endpoint: https://&lt;IP_address&gt;<br/> <br/>Preparing k8s-harness-namespace-admin-harness-conf<br/>Setting a cluster entry in kubeconfig...Cluster &#34;&lt;your_cluster_name&gt;&#34; set.<br/>Setting token credentials entry in kubeconfig...User &#34;harness-namespace-admin-harness-&lt;your_cluster_name&gt;&#34; set.<br/>Setting a context entry in kubeconfig...Context &#34;harness-namespace-admin-harness-&lt;your_cluster_name&gt;&#34; created.<br/>Setting the current-context in the kubeconfig file...Switched to context &#34;harness-namespace-admin-harness-&lt;your_cluster_name&gt;&#34;.<br/> <br/>All done! Testing with:<br/>KUBECONFIG=./kube/k8s-harness-namespace-admin-harness-conf kubectl get pods -n harness<br/>No resources found in harness namespace.</pre>
<p>When you execute this script it will create a folder called <strong>kube</strong> that contains a file named <strong>k8s-harness-namespace-admin-harness-conf</strong>.</p>
<p><span style="color:#f44e3b" data-hd-color="#f44e3b"><strong>Do not delete this file.</strong></span> You must copy this file onto the Ambassador VM at the location <code>$HOME/.kube/config</code> as described in
  <a href="#test_ambassador_connectivity_and_access_to_harness_namespace">Test Ambassador Connectivity and Access to Harness Namespace</a>.</p>
<p>To verify the <strong>harness</strong> namespace on your Kubernetes cluster, and the kubeconfig file, run the following command. Replace <code>&lt;kube-config-file&gt;</code> with the path to the kubeconfig file created above:</p>
<p><code>kubectl get namespace harness --kubeconfig=&lt;kube-config-file&gt;</code></p>
<p>None of the above commands should return an error.</p>
<p></p>
<h4>Docker Repo Secret Setup</h4>
<p>In this step, you will create a secret in the <strong>harness</strong> namespace that Kubernetes will use to access the Docker repository containing the Harness microservices images.</p>
<p></p>
<figure>
  <img src="https://files.helpdocs.io/kw8ldg1itf/articles/go5nk41qvd/1589223359585/image.png"/>
</figure>
<p>This secret will be used by the Harness microservices installed later on in
  <a href="#install_harness">Install Harness</a>.</p>
<ol>
  <li>Obtain the Docker user account user name and password. You will add these to the script file you download and run.</li>
  <li>Ensure you are on the Kubernetes cluster you created.</li>
  <li>Download the
    <a href="https://harness-onprem-resources-files.s3-us-west-1.amazonaws.com/secret.sh">secret.sh</a> file from Harness (right-click and select Save) to create the secret.</li>
  <li>Open <strong>secret.sh</strong> in a code editor and replace the repository URL, user, password, and email placeholders with your information.
    <br/>
    <br/>Here is what the placeholders look like:
    <br/>
    <br/><pre>REGISTRY_URL=&#34;&lt;your-repo-url&gt;&#34;<br/><br/>REGISTRY_USER=&#34;&lt;user&gt;&#34;<br/><br/>REGISTRY_PASS=&#34;&lt;password&gt;&#34;<br/><br/>REGISTRY_EMAIL=&#34;&lt;email&gt;&#34;</pre></li>
  <li>Execute the script.</li>
</ol>
<p>The preceding steps are for a generic Kubernetes and Docker setup; however, you might be running them on a cloud platform. Please consult the cloud platform documentation for adding a secret to the Kubernetes namespace.</p>
<p>As an example of a cloud platform setup, the next section shows the Kubernetes commands to run for a Docker setup in Google Container Registry (GCR).</p>
<h5>Alternative Example using GCR</h5>
<p>If your Docker repository was created using GCR, here is the command you would use on the Kubernetes cluster to create the secret in the <strong>harness</strong> namespace:</p><pre>$ kubectl create secret docker-registry regcred --docker-server=us.gcr.io --docker-username=_json_key --docker-password=&#34;&lt;cat the path to the keyfile.json&gt;&#34; --docker-email=&lt;email id&gt;<br/><br/>secret/regcred created</pre>
<p>Here&#39;s an example of running this command:</p><pre>$ kubectl create secret docker-registry regcred --docker-server=us.gcr.io --docker-username=_json_key --docker-password=&#34;$(cat ~/keyfile.json)&#34; --docker-email=jane.doe@harness.io<br/><br/>secret/regcred created</pre>
<p>The response should look something like this:</p><pre>kubectl describe secret regcred -n  harness<br/><br/>Name:         regcred<br/><br/>Namespace:    harness<br/><br/>Labels:       &lt;none&gt;<br/><br/>Annotations:  &lt;none&gt;<br/><br/>Type:  kubernetes.io/dockerconfigjson​<br/><br/>Data<br/><br/>====<br/><br/>.dockerconfigjson:  5686 bytes</pre>
<p></p>
<h4>Option: Store Certificate Secret in Harness Namespace</h4>
<p>If you would like TLS to terminate in the Harness Kubernetes cluster, you must provide your certificate as a secret in the cluster.</p>
<p>To perform this option, obtain the following:</p>
<ul>
  <li>The certificate in PEM (.pem) format. </li>
  <li>The private key in PEM format.</li>
  <li>A secret.yaml file in the following format (note the placeholders):</li>
</ul><pre>apiVersion: v1<br/>data:<br/> tls.crt: _FULLCHAIN_<br/> tls.key: _PRIVKEY_<br/>kind: Secret<br/>metadata:<br/> name: harness-cert<br/> namespace: harness<br/>type: kubernetes.io/tls</pre>
<p>Do the following:</p>
<ol>
  <li>Replace <code>_FULLCHAIN_</code> with the certificate in base64. You can use a command like this to convert to base64:
    <br/>
    <br/><code>cat fullchain.pem | base64</code></li>
  <li>Replace <code>_PRIVKEY_</code> with the private key in base64:
    <br/>
    <br/><code>cat privkey.pem | base64</code></li>
  <li>Apply the secret.yaml file to the <strong>harness</strong> namespace using the command:
    <br/>
    <br/><code>kubectl apply secret.yaml</code></li>
</ol>
<p>This will populate the cert as a secret and the Harness load balancer should pick it up and use it. Please let Harness know if you have any questions.</p>
<p>Now that the Docker and Kubernetes components are set up, you can set up the Harness Ambassador VM that manages Harness On-Prem installations.</p>
<h4>Ambassador Virtual Machine Setup</h4>
<p>The Harness Cloud uses the Ambassador to manage the installation of Harness On-Prem&#39;s Docker images and their set up in your Kubernetes <strong>harness</strong> namespace.</p>
<p></p>
<figure>
  <img src="https://files.helpdocs.io/kw8ldg1itf/articles/go5nk41qvd/1589224047753/image.png"/>
</figure>
<p>In this step we will test the connections from the Ambassador VM to the components you have set up, and then install the Ambassador.</p>
<div class="note-callout">Harness recommends not running the Harness Ambassador as root. Please create a dedicated user for it. If you are running the Harness Ambassador in Kubernetes or Docker, then you must run it as root.</div>
<p></p>
<ol>
  <li>Ensure the Ambassador VM meets the requirements described in
    <a href="#harness_ambassador_vm_requirements">Harness Ambassador VM Requirements</a>.</li>
  <li>Ensure the Ambassador is running on a dedicated VM.</li>
</ol>
<p>Perform the steps in the following sections.</p>
<h5>Test Outbound Connections</h5>
<p>The Harness Ambassador VM requires outbound network connectivity to <strong>app.harness.io</strong> over port <strong>443</strong>.</p>
<p></p>
<figure>
  <img src="https://files.helpdocs.io/kw8ldg1itf/articles/go5nk41qvd/1589224258372/image.png" style="max-height:50%;max-width:50%" data-hd-height="50%" data-hd-width="50%"/>
</figure>
<p></p>
<ol>
  <li>Test outbound connectivity from the Ambassador machine:
    <br/>
    <br/><code>nc -vz app.harness.io 443</code></li>
</ol>
<p>The <code>nc</code> command output should provide no errors and look like this:</p>
<p><code>Connection to app.harness.io port 443 [tcp/https] succeeded!</code></p>
<p></p>
<h5>Ambassador Installation</h5>
<p>Once you have verified the Ambassador VM meets the system and networking requirements, you can install and start the Ambassador.</p>
<ol>
  <li>Extract Ambassador:
    <ol>
      <li>Log into VM as your Harness dedicated user.</li>
      <li>Copy the Ambassador installer provided by Harness to the Ambassador VM.</li>
      <li>Extract the installer: <code>tar -xvf harness-ambassador.tar.gz</code>.</li>
      <li>If you need to configure proxy settings, run <code>setup-proxy.sh</code>.</li>
    </ol>
  </li>
  <li>Start Ambassador:
    <ol>
      <li>Open the extracted Ambassador folder.</li>
      <li>Run the start script: <code>start_ambassador.sh</code>.</li>
    </ol>
  </li>
</ol>
<p></p>
<h5>Configure Docker Login for the Ambassador</h5>
<p>The Ambassador uses a Docker user account to log into the Docker repository and run the Docker commands to add the Harness On-Prem images.</p>
<p></p>
<figure>
  <img src="https://files.helpdocs.io/kw8ldg1itf/articles/go5nk41qvd/1589224417358/image.png"/>
</figure>
<ol>
  <li>Ensure you are logged into the Ambassador VM with the same account you used to install and run the Ambassador.</li>
  <li>Run the following command, replacing <code>&lt;repository_url&gt;</code> with the URL of your Docker repository:
    <br/>
    <br/><code>docker login &lt;repository_url&gt;</code></li>
</ol>
<p>You are prompted for the Docker user account username and password. Enter these and verify the login was successful.</p>
<p>The preceding steps are for generic Docker setup; however, you might be running Docker on a cloud platform. Please consult the cloud platform documentation for remote login.</p>
<p>As an example of a cloud platform setup, the next section shows the gcloud commands to run for a Docker setup in Google Container Registry (GCR).</p>
<h5>GCR Docker Login Example</h5>
<p>If you have used GCR to create the Docker Repository, you can use the following examples to log into Docker repo.</p>
<p>First, here is an example of creating the key:</p><pre>gcloud iam service-accounts keys create keyfile.json --iam-account packer-builder-username@playground.iam.gserviceaccount.com</pre>
<p>The output should look something like this:</p><pre>Response: created key [3ea7ce42d5fe26a453xssx5c9ef9e5dd40d25] of type [json] as [keyfile.json] for [packer-builder-username@playground.iam.gserviceaccount.com]</pre>
<p>Next, we log in using the key:</p><pre>cat keyfile.json | docker login -u _json_key --password-stdin https://us.gcr.io</pre>
<p>After you run the above command, you should see the message <strong>login succeeded</strong>.</p>
<p>See
  <a href="https://cloud.google.com/container-registry/docs/advanced-authentication#token">Access token</a> from GCP for Docker login info.</p>
<h5>Verify Docker User Permissions</h5>
<p>The Docker user configured on the Ambassador should have permissions to <span><strong>read</strong></span>, <strong>write</strong>, and <strong>create</strong> new repositories on the Docker registry. </p>
<div class="note-callout">If the user lacks the permission to create new folders, contact Harness Support to pre-create the repositories for the installation.</div>
<ol>
  <li>Check Write Permission by running these commands:
    <br/>
    <br/><pre>docker pull nginx:latest (Pull from docker nginx repo )<br/><br/>​docker tag ngnix:latest&lt;your_repo&gt;/nginx:latest<br/><br/>docker push &lt;your_repo&gt;/nginx:latest</pre></li>
  <li>Check Read Permission:
    <br/>
    <br/><pre>docker pull &lt;your_repo&gt;/nginx:latest<br/><br/>docker pull us.gcr.io/playground-123/k8s-on-prem/nginx:latest</pre></li>
</ol>
<p>The output looks like this:</p><pre>docker registry ls REPOSITORY[:TAG] [OPTIONS]</pre>
<p></p>
<h5>Test Ambassador Connectivity and Access to Harness Namespace</h5>
<p>In this step, you will copy the kubeconfig file you created in
  <a href="#kubernetes_config_file_setup">Kubernetes Config File Setup</a> to the Ambassador.</p>
<p>Next, you use the file to connect the Ambassador to the <strong>harness</strong> namespace in the Kubernetes cluster.</p>
<p></p>
<figure>
  <img src="https://files.helpdocs.io/kw8ldg1itf/articles/go5nk41qvd/1589224946239/image.png"/>
</figure>
<p>As noted in
  <a href="#harness_ambassador_vm_requirements">Harness Ambassador VM Requirements</a>, the kubectl command interface should be installed on the Ambassador VM.</p>
<ol>
  <li>On the machine where you created the Kubernetes <strong>harness</strong> namespace, copy the <strong>k8s-harness-namespace-admin-harness-conf</strong> file you created in
    <a href="#kubernetes_config_file_setup">Kubernetes Config File Setup</a>.</li>
  <li>On the Ambassador, paste the file in this location: <code>$HOME/.kube/config</code></li>
  <li>On the Ambassador, run the following command to ensure connectivity and access to the <strong>harness</strong> namespace in the cluster:
    <br/>
    <br/><code>kubectl get pods -n harness</code></li>
</ol>
<p>The output should look something like this:</p><pre>Response : No resources found in harness namespace.</pre>
<p>Login was successful and the <strong>harness</strong> namespace is located.</p>
<p>Now that the Ambassador is set up, you can configure the load balancer for accepting traffic to the Kubernetes cluster.</p>
<h4>Load Balancer Setup</h4>
<p>You need to pick a method for sending traffic into the Harness Kubernetes On-Prem cluster that best suits your needs.</p>
<p>This step discusses the options available.</p>
<h5>Cluster IP</h5>
<p>Use this method if you have an Ingress controller in Kubernetes and a load balancer already pointing to it. This is a common method when Harness On-Prem customers have multiple applications in the same Kubernetes cluster.</p>
<p>You are responsible for creating an Ingress rule from your Ingress controller to the Harness Ingress controller.</p>
<p>The Harness DNS domain name you use ( for example, <strong>mycompany.harness.io</strong>) must resolve to your Ingress controller.</p>
<h5>Load Balancer</h5>
<p>Use this method if you do not have a load balancer or Ingress controller set up, and the Kubernetes cluster is running in a cloud provider that supports automatic load balancer creation (AMS, GCP, Azure). This is typical for new Kubernetes installations
  in the cloud.</p>
<p>You are responsible for providing Harness with a static IP used by the load balancer. In some cases, customers need to provide annotations for the automatic load balancer creation.</p>
<p>You will map the Harness DNS domain name you use to the static IP of the load balancer.</p>
<h5>Node Port</h5>
<p>Use this method if you have your own load balancer external to Kubernetes (F5, A10, etc).</p>
<p>You are responsible for providing Harness with a node port to use, and you must map your load balancer service to route traffic to Harness On-Prem.</p>
<p>The Harness DNS domain name you use must point to the external load balancer.</p>
<h5>TLS Considerations</h5>
<p>Harness recommends that all access to Harness On-Prem microservices be encrypted using TLS. All of the load balancing options mentioned above support TLS termination.</p>
<p>Here are the two TLS options:</p>
<ul>
  <li><strong>Terminate TLS inside Harness On-Prem</strong> — In this configuration, you will provide Harness On-Prem with a certificate as a secret in your Kubernetes cluster. Harness On-Prem will use this certificate to encrypt all traffic to and from Harness
    On-Prem.</li>
  <li><strong>Terminate TLS outside of Harness On-Prem</strong> — In this configuration, Harness On-Prem will accept unencrypted traffic. It is your responsibility to terminate TLS up-stream from Harness On-Prem. Some unencrypted traffic from your load balancer
    to Harness is required (over port 80) in this scenario.</li>
</ul>
<p></p>
<h4>Avoid Common Issues</h4>
<p>This step is a quick review and verification of certain critical configuration settings.</p>
<h5>TLS and Harness Integration</h5>
<ol>
  <li>Review the TLS options discussed in
    <a href="#tls_considerations">TLS Considerations</a>, and decide on an option.</li>
  <li>Test your TLS connections to ensure there are no issues with certificate verification.</li>
</ol>
<h5>Create Docker Login for Harness Ambassador</h5>
<ol>
  <li>Ensure that you have created a Docker user account on the Docker repo for the Harness Ambassador as described in
    <a href="#configure_docker_login_for_the_ambassador">Configure Docker Login for the Ambassador</a>.</li>
  <li>Ensure that you test the login credentials and verify that the Ambassador VM account can log into Docker.</li>
</ol>
<h5>Grant Docker Permissions for Harness Ambassador</h5>
<ol>
  <li>Ensure that the Docker repository user account has permissions to <strong>read</strong>, <strong>write</strong>, and <strong>create</strong> new repositories on the Docker registry.</li>
</ol>
<p>If the user account lacks the permission to create new folders in the repository, contact Harness Support to pre-create the repositories for the installation.</p>
<h5>Create Secret in Kubernetes Cluster for Accessing the Docker Repo</h5>
<ol>
  <li>Ensure that you have created a secret in the <strong>harness</strong> namespace to access the Docker repository that contains the Harness microservices images. This is described in
    <a href="#docker_repo_secret_setup">Docker Repo Secret Setup</a>.</li>
</ol>
<h5>Create a Kubeconfig File and Place it on the Ambassador</h5>
<ol>
  <li>Ensure that you created the kubeconfig file as described in
    <a href="#kubernetes_config_file_setup">Kubernetes Config File Setup</a>.</li>
  <li>Ensure that you copied the file to the Ambassador VM location: <code>$HOME/.kube/config</code>.</li>
</ol>
<p>If you have not done so already, run the following command to ensure connectivity and access to the <strong>harness</strong> namespace in the cluster:</p>
<p><code>kubectl get pods -n harness</code></p>
<p>The output should look something like this:</p><pre> Response : No resources found in harness namespace.</pre>
<h4>Send Information to Harness</h4>
<p>Once the infrastructure is prepared, Harness installation involves the following steps:</p>
<p>
  <a href="mailto:support@harness.io">Email</a> the following details to the Harness Team:</p>
<ul>
  <li><strong>Repository URL</strong> — Internal URL used by the Ambassador and Kubernetes cluster. Include <code>http(s)://</code> scheme.</li>
  <li><strong>Load Balancer URL</strong> — Internal URL used by the Ambassador and Kubernetes cluster.  Include <code>http(s)://</code> scheme.</li>
  <li><strong>StorageClass</strong> — For example, standard, gp2, etc. Select a storage class used for pods that need permanent storage.</li>
</ul>
<div class="tip-callout"><strong>Best Practice</strong> — To avoid data loss in the event the Harness namespace or database PVCs are deleted, use a storage class with <code>reclaimPolicy: Retain</code>. If you don&#39;t have a storage class with that setting you can copy an existing
  storage class&#39;s YAML, set the <code>reclaimPolicy</code>, and give it a new name. This is the name you will provide to Harness.</div>
<ul>
  <li><strong>Ingress controller type and port</strong> — Loadbalancer, NodePort, or ClusterIP, and port number.</li>
  <li><strong>SSL Termination endpoint</strong> — Please confirm SSL is terminated on your load balancer.</li>
  <li><strong>Internal Ambassador VM Hostname</strong> — Output of the command <code>hostname</code>. Used by Harness to identify the Ambassador in Harness records.</li>
  <li><strong>Internal Ambassador VM IP Address</strong> — Output of the command <code>hostname -i</code>. Used by Harness to identify the Ambassador in their records</li>
</ul>
<p></p>
<h4>Install Harness</h4>
<p>Once you provide the above information, Harness Support will perform the installation. This process includes: </p>
<ol>
  <li>Validating the connectivity of the Ambassador to the Harness Cloud.</li>
  <li>The Harness Team runs pre-install checks.</li>
  <li>Next, the Harness Team triggers the installation of the On-Prem platform on your Kubernetes cluster, as configured.</li>
  <li>The Harness Team runs a post-install Workflow to verify that Harness On-Prem is working as expected.</li>
  <li>Notify you that the installation is complete.</li>
</ol>
<p></p>
<h3>Post-Installation</h3>
<p>Once Harness Support has verified the installation, do the following:</p>
<ol>
  <li>Log into the Harness Manager using the Admin setup link. Replace <code>LOAD_BALANCER_URL</code> with your URL:
    <br/>
    <br/><code>https://LOAD_BALANCER_URL/#/onprem-signup</code></li>
  <li>In the resulting signup form, set up the initial admin account by entering the requested details.
    <br/>
    <br/>All subsequent logins will go to the standard URL: <code>https://LOAD_BALANCER_URL</code></li>
  <li>Log into the account using the load-balancer URL: <code>https://LOAD_BALANCER_URL</code></li>
</ol>
<p>The Harness On-Prem application should open successfully.</p>
<h3>Important Next Steps</h3>
<div class="note-callout"><strong>Important:</strong> You cannot invite other users to Harness until a Harness Delegate is installed and a Harness SMTP Collaboration Provider is configured.</div>
<ol>
  <li>Install the Harness Delegate:
    <a href="/article/h9tkwmkrm7-delegate-installation">Delegate Installation and Management</a>.</li>
  <li>Set up an SMTP Collaboration Provider in Harness for email notifications from the Harness Manager:
    <a href="/article/8nkhcbjnh7-add-smtp-collaboration-provider">Add SMTP Collaboration Provider</a>.
    <br/>Ensure you open the correct port for your SMTP provider, such as
    <a href="https://support.office.com/en-us/article/server-settings-you-ll-need-from-your-email-provider-c82de912-adcc-4787-8283-45a1161f3cc3" target="_blank">Office 365</a>.</li>
  <li>
    <a href="/article/uuer539u3l-add-a-secrets-manager">Add a Harness Secrets Manager</a>. By default, On-Prem installations use the local Harness MongoDB for the default Harness Secrets Manager. This is not recommended.
    <br/>
    <br/>After On-Prem installation, configure a new Secret Manager (Vault, AWS, etc). You will need to open your network for the Secret Manager connection.</li>
</ol>
<h3>Notes</h3>
<p>Harness On-Prem installations do not currently support the Harness
  <a href="/article/6n7fon8rit-using-the-helm-delegate">Helm Delegate</a>.</p>
<p></p>
<p></p>
<p></p>
<p></p>
<p></p>
<p></p>
<p></p>
<p></p>
<p></p>
<p></p>
<p></p>