type: article
article_id: d959kzrl39
user_id: mfr0nxh4be
category_id: ep5nt3dyrb
author:
  name: Michael Cretzman
  profile_image: https://www.gravatar.com/avatar/2e8616837f4ee92be5d19ffe9b9ccba9?d=mm&s=150
title: 4 - Verify Deployments with Custom APMs and Logs
slug: 2-verify-deployments-with-custom-apms
description: How to add a custom metrics or log provider to a Harness Workflow, where
  Harness can analyze the provider's data to verify, rollback, and improve deployments.
short_version: Harness can analyze Custom APM data to verify, rollback, and improve
  deployments.
tags:
- Verification Provider
- verification
- APM
- application performance monitoring
- Deployment Verification
- setup
- log
- Workflow
- Metrics Provider
- risk analysis
show_toc: true
is_private: false
is_published: false
is_featured: false
stale_status:
  is_stale: false
  reason: Article updated
  source: API
  triggered_at: 2021-05-12T17:22:46.253963Z
  expires_at: null
permission_groups: []
multilingual:
- language_code: en
  title: 4 - Verify Deployments with Custom APMs and Logs
  description: How to add a custom metrics or log provider to a Harness Workflow,
    where Harness can analyze the provider's data to verify, rollback, and improve
    deployments.
  short_version: Harness can analyze Custom APM data to verify, rollback, and improve
    deployments.
  body: |-
    <p>The following procedure describes how to add a custom APM (metrics) or Logs verification step in a Harness Workflow. For more information about Workflows, see <a href="/article/m220i1tnia-workflow-configuration">Add a Workflow</a>.</p><p>Once you run a deployment and your custom metrics or logs provider obtains its data, Harness machine-learning verification analysis will assess the risk level of the deployment using the data from the provider.</p><div class="tip-callout">In order to obtain the names of the host(s), pod(s), or container(s) where your service is deployed, the verification provider should be added to your Workflow <em>after</em> you have run at least one successful deployment.</div><h3>Deployment Verification Setup</h3><p>To verify your deployment with a custom metric or log provider, do the following:</p><ol><li>Ensure that you have added Custom Metrics or Logs Provider as a verification provider, as described in <a href="/article/9xvrgqy2dd-1-custom-verification-connection-setup">1 – Custom Verification Connection Setup</a>.</li><li>In your workflow, under <strong>Verify Service</strong>, click <strong>Add Verification</strong>.<figure><img src="https://files.helpdocs.io/kw8ldg1itf/articles/uw64fijctw/1535478536625/image.png"/></figure></li><li>In the resulting <strong>Add Step</strong> settings, select either <strong>Performance Monitoring</strong> &gt; <strong>Custom Metrics</strong> or <strong>Log Analysis</strong> &gt; <strong>Custom Log Verification</strong>.</li><li>Click <strong>Next</strong>. The <strong>Configure </strong><strong>Custom Metrics</strong> or <strong>Configure </strong><strong>Custom Log Verification</strong> settings appear.<br/><table class="borderless"><tbody><tr><td style="padding-left:0 !important"><p></p><figure><img src="https://files.helpdocs.io/kw8ldg1itf/articles/aat5m8p6ss/1582772316321/image.png"/></figure></td><td style="padding-left:0 !important"><p></p><figure><img src="https://files.helpdocs.io/kw8ldg1itf/articles/d959kzrl39/1580940641475/image.png"/></figure></td></tr></tbody></table></li></ol><p>As you can see, the settings are the same except for the <a href="#metric_collections_settings">Metric Collections Settings</a> and <a href="#log_collection_settings">Log Collections Settings</a> sections. For other, common settings, see <a href="#common_settings">Common Settings</a>.</p><h4>Metric Collections Settings</h4><ol><li>In <strong>Metrics Data Provider</strong>, select the custom metric provider you added, described in <a href="/article/9xvrgqy2dd-1-custom-verification-connection-setup">1 - Custom Verification Connection Setup</a>.</li><li>In <strong>Metrics Type</strong>, select <strong>Infrastructure</strong> or <strong>Transaction</strong>.</li><li>Add a <strong>Metric Collections</strong> section.<figure><img src="https://files.helpdocs.io/kw8ldg1itf/articles/d959kzrl39/1580940988572/image.png" style="max-height:50%;max-width:50%" data-hd-height="50%" data-hd-width="50%"/></figure></li></ol><p><strong>Metric Collections</strong> are covered in the following table.</p><table><tbody><tr><td><p><strong>Field</strong></p></td><td><p><strong>Description</strong></p></td></tr><tr><td><p><strong>Metrics Name</strong></p></td><td><p>Enter a name for the type of error you are collecting, such as <strong>HttpErrors</strong>.</p></td></tr><tr><td><p><strong>Metrics Type</strong></p></td><td><p>For the <strong>Infrastructure</strong> Metrics Type, select the type of metric you want to collect:</p><ul><li><strong>Infra</strong> -–Infrastructure metrics, such as CPU, memory, and HTTP errors.</li><li><strong>Value</strong> – <a href="https://docs.newrelic.com/docs/apm/new-relic-apm/apdex/apdex-measure-user-satisfaction" target="_blank">Apdex</a> (measures user satisfaction with response time).</li><li><strong>Lower Value</strong> – Values below the average.</li></ul><p>For the <strong>Transaction</strong> Metrics Type, select the type of metric you want to collect:</p><ul><li>Error</li><li>Response Time</li><li>Throughput</li></ul></td></tr><tr><td><p><strong>Metrics Collection URL</strong></p></td><td><p>Enter a query for your verification. You can simply make the query in your Verification Provider and paste it in this field. For example, in New Relic Insights, you might have the following query:</p><figure><img src="https://files.helpdocs.io/kw8ldg1itf/articles/27w7uso9r4/1536084078382/image.png"/></figure><p>You can paste the query into the <strong>Metrics Collection URL</strong> field:</p><figure><img src="https://files.helpdocs.io/kw8ldg1itf/articles/27w7uso9r4/1536084138311/image.png"/></figure><p>For information on New Relic Insights NRSQL, see <a href="https://docs.newrelic.com/docs/insights/nrql-new-relic-query-language/nrql-resources/nrql-syntax-components-functions" target="_blank">NRQL syntax, components, functions</a> from New Relic.The time range for a query (<strong>SINCE</strong> clause in our example) should be less than 5 minutes to avoid overstepping the time limit for some verification providers.</p><p>Most often, when you create your query, you will include a hostname placeholder in the query, <code>${host}</code>. This placeholder will be used later when setting up the <strong>Metrics Value</strong> and other settings that use <strong>Guide from an example</strong>.</p><p>For example, if your query is:</p><p><code>SELECT count(host) FROM Transaction SINCE 30 MINUTES AGO COMPARE WITH 1 WEEK AGO WHERE host = &#39;37c444347ac2&#39; TIMESERIES</code></p><p>Then you replace the host name with the <code>${host}</code> placeholder and paste the query into <strong>Metrics Collection URL</strong>:</p><p><code>SELECT count(host) FROM Transaction SINCE 30 MINUTES AGO COMPARE WITH 1 WEEK AGO WHERE host = &#39;${host}&#39; TIMESERIES</code></p><p>Make sure the <code>${start_time_seconds}</code> and <code>${end_time_seconds}</code> parameters are included in the query.</p><p>These variables define a 1-minute interval from the time the Workflow Verification starts. To modify the time interval, click <strong>Edit Step</strong> &gt; <strong>APM</strong> &gt; <strong>Custom</strong> and update the Data Collection Interval in minutes field.</p><p>An example part of the query with these values appears as follows:</p><p><code>from=${start_time_seconds}&amp;to=${end_time_seconds}</code></p><p>For verification providers that accept values in milliseconds, you can use the <code>${start_time}</code> and <code>${end_time}</code> variables.</p><p></p></td></tr><tr><td><p><strong>Metrics Method</strong></p></td><td><p>Select <strong>GET</strong> or <strong>POST</strong>. If you select POST, the <strong>Metric Collection Body</strong> field appears.</p><p></p><figure><img src="https://files.helpdocs.io/kw8ldg1itf/articles/d959kzrl39/1580949428977/image.png" style="max-height:100%;max-width:100%" data-hd-height="100%" data-hd-width="100%"/></figure><p>In <strong>Metric Collection Body</strong>, enter the JSON body to send as a payload when making a REST call to the APM Provider. The requirements of the JSON body will depend on your APM provider.</p><p>You can use variables you created in the Service and Workflow in the JSON, as well as <a href="/article/9dvxcegm90-variables">Harness built-in variables</a>.</p></td></tr><tr><td><p><strong>Response Mapping Transaction Name</strong></p></td><td><p>These settings are for specifying which JSON fields in the responses to use.</p><p>Select <strong>Fixed</strong> or <strong>Dynamic</strong>.</p><p><strong>Fixed:</strong> Use this option when all metrics are for the same transaction. For example, a single login page.</p><p><strong>Dynamic:</strong> Use this option when the metrics are for multiple transactions.</p></td></tr><tr><td><p><strong>Name</strong></p></td><td><p>Fixed</p><p>Enter the name with which you want to identify the transaction.</p></td></tr><tr><td><p><strong>Transaction Name Path</strong></p></td><td><p>Dynamic</p><p>This is the JSON label for identifying a transaction name. In the case of our example New Relic Insights query, the FACET clause is used to group results by the attribute <strong>transactionName</strong>. You can obtain the field name that records the <strong>transactionName</strong> by using the <strong>Guide from an example</strong> feature:</p><ol><li>Click <strong>Guide from an example</strong>. The <strong>Select Key from Example</strong> popover appears.<figure><img src="https://files.helpdocs.io/kw8ldg1itf/articles/d959kzrl39/1580949200459/image.png" style="max-height:100%;max-width:100%" data-hd-height="100%" data-hd-width="100%"/></figure>The Metrics URL Collection is based on the query you entered in the <strong>Metric Collection URL field</strong> earlier.</li><li>In <strong>${host}</strong>, select a host to query. Click the query next to <strong>GET</strong> to see how the host you selected replaces the <code>${host}</code> placeholder in your query.</li><li>Click <strong>SEND</strong>. The query is executed and the JSON is returned.</li><li>Locate the field name that is used to identify transactions. In our New Relic Insights query, it is the <strong>facets.name</strong> field.<br/>If no metrics are found, you will see a <code>METRIC DATA NOT FOUND</code> error.<br/> In New Relic Insights, you can find the name in the JSON of your query results.<figure><img src="https://files.helpdocs.io/kw8ldg1itf/articles/27w7uso9r4/1536095120978/image.png" style="max-height:25%;max-width:25%" data-hd-height="25%" data-hd-width="25%"/></figure></li><li>Click the field <strong>name</strong> under facets. The field path is added to the <strong>Transaction Name Path</strong> field.<figure><img src="https://files.helpdocs.io/kw8ldg1itf/articles/27w7uso9r4/1536095167499/image.png"/></figure></li></ol></td></tr><tr><td><p><strong>Regex to transform Transaction Name</strong></p></td><td><p>Dynamic</p><p>Enter a regex expression here to obtain the specific name from the transaction path.</p><p>For example, if your Transaction Name Path JSON evaluated to a value such as <code>name : TxnName</code>, you can write a regex to remove everything other than <code>TxnName</code>.</p><p>For example <code>(name:(.*),)</code> or <code>(?&lt;=:).*(?=,)</code>.</p></td></tr><tr><td><p><strong>Metrics Value</strong></p></td><td><p>Specify the value for the event count. This is used to filter and aggregate data returned in a SELECT statement. To find the correct label for the value, do the following:</p><ol><li>Click <strong>Guide from an example</strong>. The example popover appears.<br/>The Metrics URL Collection is based on the query you entered in the <strong>Metric Collection URL field</strong> earlier. The <strong>${host}</strong> field refers to the <code>${host}</code> variable in your query.</li><li>Click <strong>Submit</strong>. The query is executed and the JSON is returned.<br/>If no metrics are found, you will see a <code>METRIC DATA NOT FOUND</code> error.</li><li>Locate the field name that is used to count events. In our New Relic Insights query, it is the <strong>facets.timeSeries.results.count</strong> field.<br/>In New Relic Insights, you can find the name in the JSON of your query results.<figure><img src="https://files.helpdocs.io/kw8ldg1itf/articles/27w7uso9r4/1536095067758/image.png" style="max-height:25%;max-width:25%" data-hd-height="25%" data-hd-width="25%"/></figure></li><li>Click the name of the field <strong>count</strong>. The field path is added to the <strong>Metrics Value</strong> field.<figure><img src="https://files.helpdocs.io/kw8ldg1itf/articles/27w7uso9r4/1536095193376/image.png"/></figure></li></ol></td></tr><tr><td><p><strong>Hostname JSON path</strong></p></td><td><p>(Displayed if <code>${host}</code> is present in the <strong>Metrics Collection URL query</strong>)</p><p>Use <strong>Guide from an example</strong> to select a host and query your APM. Click the name of the hostname JSON label in the response.</p><p>If there is no hostname in the response, leave this setting empty.</p></td></tr><tr><td><p><strong>Timestamp</strong></p></td><td><p>Specify the value for the timestamp in the query. To find the correct label for the value, do the following:</p><ol><li>Click <strong>Guide from an example</strong>. The <strong>Select Key from Example</strong> popover appears.<br/>The Metrics URL Collection is based on the query you entered in the <strong>Metric Collection URL field</strong> earlier.</li><li>Click <strong>Submit</strong>. The query is executed and the JSON is returned.</li><li>Locate the field name that is used for the time series <strong>endTimeSeconds</strong>. In our New Relic Insights query, it is the <strong>facets.timeSeries.endTimeSeconds</strong> field.<br/>In New Relic Insights, you can find the name in the JSON of your query results.<figure><img src="https://files.helpdocs.io/kw8ldg1itf/articles/27w7uso9r4/1536095482626/image.png" style="max-height:50%;max-width:50%" data-hd-height="50%" data-hd-width="50%"/></figure></li><li>Click the name of the field <strong>endTimeSeconds</strong>. The field path is added to the <strong>Timestamp</strong> field.<figure><img src="https://files.helpdocs.io/kw8ldg1itf/articles/27w7uso9r4/1536095551864/image.png"/></figure></li></ol></td></tr><tr><td><p><strong>Timestamp Format</strong></p></td><td><p>Enter the format of the timestamp included in the query <em>request</em> (not response), set in <strong>Timestamp</strong>. The format follows the <a href="https://docs.oracle.com/javase/8/docs/api/java/text/SimpleDateFormat.html" target="_blank">Java SimpleDateFormat</a>. For example, a timestamp syntax might be <strong>yyyy-MM-dd&#39;T&#39;HH:mm:ss.SSSX</strong>. If you leave this field empty, Harness will use the default range of 1 hour previous (now-1h) to now.</p></td></tr></tbody></table><p>When you are done, the settings will look something like this:</p><p></p><p></p><figure><img src="https://files.helpdocs.io/kw8ldg1itf/articles/d959kzrl39/1580941536467/image.png" style="max-height:50%;max-width:50%" data-hd-height="50%" data-hd-width="50%"/></figure><p></p><div class="hd--md" data-hd-markdown="&lt;span id=&#34;log_collection_settings&#34;&gt;&lt;/span&gt;"><p><span id="log_collection_settings"></span></p>
    </div><h4>Log Collections Settings</h4><ol><li>In <strong>Log Data Provider</strong>, select the custom logs provider you added, described in  <a href="/article/9xvrgqy2dd-1-custom-verification-connection-setup">1 – Custom Verification Connection Setup</a>.</li><li>Click <strong>Add Log Collection</strong> to add a <strong>Log Collection</strong> section.<figure><img src="https://files.helpdocs.io/kw8ldg1itf/articles/1dq1n1k99s/1586217053066/image.png" style="max-height:50%;max-width:50%" data-hd-height="50%" data-hd-width="50%"/></figure></li></ol><ul><li>In <strong>Request Method</strong>, select <strong>GET</strong> or <strong>POST</strong>.</li><li>In <strong>Search URL</strong>, enter the API query that will return a JSON response.<br/>Make sure the following parameters are included in the query. These placeholders will be replaced with the actual values during the execution.<ol><li> <code>${start_time}</code> or <code>${start_time_seconds</code>}: This is the placeholder parameter to specify the start time of the query. It is similar to the value specified in custom metrics verification.</li><li> <code>${end_time}</code> or <code>${end_time_seconds}</code>: This is the placeholder parameter to specify the end time of the query. It is similar to the value specified in custom metrics verification.</li><li> <code>${host}</code>: This is the placeholder for querying based on the host during deployment verification. This is NOT a required field if the setup is for a Previous Analysis.</li></ol><br/>In the remaining settings, you will map the keys in the JSON response to Harness settings to identify where data—such as log message and timestamp—are located in the JSON response.</li><li>In <strong>Search Body</strong>, enter any JSON search input for your query. If you need to send a token, but do not want to send it in plaintext, you can use a Harness <a href="/article/au38zpufhr-secret-management#encrypted_text">encrypted text secret</a>.</li><li>In <strong>Response Type</strong>, select <strong>JSON</strong>.</li><li>In <strong>Log Message JSON Path</strong> – Use <strong>Guide from Example</strong> to query the log provider and return the JSON response.<figure><img src="https://files.helpdocs.io/kw8ldg1itf/articles/1dq1n1k99s/1586219550272/image.png" style="max-height:100%;max-width:100%" data-hd-height="100%" data-hd-width="100%"/></figure></li></ul><p>The URL is a combination of the Verification Cloud Provider <strong>Base URL</strong> and the <strong>Log Collection URL</strong> you entered.</p><p>Click <strong>SEND</strong>. In the JSON response, click the key that includes the log message path.</p><p></p><figure><img src="https://files.helpdocs.io/kw8ldg1itf/articles/27w7uso9r4/1562885301673/image.png" style="max-height:50%;max-width:50%" data-hd-height="50%" data-hd-width="50%"/></figure><p>The log message path key is added to <strong>Log Message JSON Path</strong>:</p><p></p><figure><img src="https://files.helpdocs.io/kw8ldg1itf/articles/27w7uso9r4/1562885323848/image.png" style="max-height:50%;max-width:50%" data-hd-height="50%" data-hd-width="50%"/></figure><ul><li><strong>Hostname JSON Path</strong> – Use <strong>Guide from Example</strong> to query the log provider and return the JSON response. In the JSON response, click the key that includes the hostname path.</li></ul><p></p><figure><img src="https://files.helpdocs.io/kw8ldg1itf/articles/27w7uso9r4/1562885361223/image.png" style="max-height:50%;max-width:50%" data-hd-height="50%" data-hd-width="50%"/></figure><ul><li><strong>Regex to Transform Host Name</strong> – If the JSON value returned requires transformation in order to be used, enter the regex expression here. For example: If the value in the host name JSON path of the response is <code>pod_name:harness-test.pod.name</code> and the actual pod name is simply <code>harness-test.pod.name</code>, you can write a regular expression to remove the <code>pod_name</code> from the response value.</li><li><strong>Timestamp JSON path</strong> – Use <strong>Guide from Example</strong> to query the log provider and return the JSON response. In the JSON response, click the key that includes the timestamp.</li></ul><p></p><figure><img src="https://files.helpdocs.io/kw8ldg1itf/articles/27w7uso9r4/1562885442593/image.png" style="max-height:50%;max-width:50%" data-hd-height="50%" data-hd-width="50%"/></figure><ul><li><strong>Timestamp Format</strong> – Enter the format of the timestamp included in the query request (not response). The format follows the <a href="https://docs.oracle.com/javase/8/docs/api/java/text/SimpleDateFormat.html" target="_blank">Java SimpleDateFormat</a>. For example, a timestamp syntax might be <strong>yyyy-MM-dd&#39;T&#39;HH:mm:ss.SSSX</strong>. If you leave this field empty, Harness will use the default range of 1 hour previous (now - 1h) to now.</li></ul><p>Click <strong>Add</strong>. The Log Collection is added.</p><p></p><div class="hd--md" data-hd-markdown="&lt;span id=&#34;custom_thresholds&#34;&gt;&lt;/span&gt;"><p><span id="custom_thresholds"></span></p>
    </div><h4>Custom Thresholds</h4><p>In the <strong>Configure </strong><strong>Custom Metrics</strong> dialog, you can access the <strong>Custom Thresholds</strong> section once you have configured at least one Metrics Collection. You can use Custom Thresholds to define two types of rules that override normal verification behavior:</p><ul><li><strong>Ignore Hints</strong> that instruct Harness to skip certain metrics/value combinations from verification analysis.</li><li><strong>Fast-Fail Hints</strong> that cause a Workflow to enter a failed state.</li></ul><p>For details about defining Custom Thresholds, see <a href="/article/z2n6mnf7u0-custom-thresholds">Apply Custom Thresholds to Deployment Verification</a>.</p><div class="tip-callout">In deployment, where a Fast-Fail Hint moves a Workflow to a failed state, the Workflow&#39;s Details panel for that Verification step will indicate the corresponding threshold.</div><p></p><div class="hd--md" data-hd-markdown="&lt;span id=&#34;common_settings&#34;&gt;&lt;/span&gt;"><p><span id="common_settings"></span></p>
    </div><h4>Common Settings</h4><p>The following settings are common to both metrics and log providers.</p><table><tbody><tr><td><p><strong>Field</strong></p></td><td><p><strong>Description</strong></p></td></tr><tr><td><p><strong>Expression for Host/Container</strong></p></td><td><p>The expression entered here should resolve to a host/container name in your deployment environment. By default, the expression is <strong>${instance.host.hostName}</strong>.</p></td></tr><tr><td><p><strong>Analysis Time Duration</strong></p></td><td><p>Set the duration for the verification step. If a verification step exceeds the value, the workflow <a href="/article/m220i1tnia-workflow-configuration#failure_strategy">Failure Strategy</a> is triggered. For example, if the Failure Strategy is <strong>Ignore</strong>, then the verification state is marked <strong>Failed</strong> but the workflow execution continues.</p><p>Harness waits 2-3 minutes before beginning the analysis to avoid initial deployment noise. This is a standard with monitoring tools.</p></td></tr><tr><td><p><strong>Data Collection Interval</strong></p></td><td><p>Specify the frequency at which Harness will run the query. Harness recommends the value 2.</p></td></tr><tr><td><p><strong>Baseline for Risk Analysis</strong></p></td><td><p>See <a href="/article/0avzb5255b-cv-strategies-and-best-practices">CV Strategies, Tuning, and Best Practices</a>.</p></td></tr><tr><td><p><strong>Execute with previous steps</strong></p></td><td><p>Check this checkbox to run this verification step in parallel with the previous steps in <strong>Verify Service</strong>.</p></td></tr><tr><td><p><strong>Failure Criteria</strong></p></td><td><p>Specify the sensitivity of the failure criteria. When the criteria is met, the workflow <strong>Failure Strategy</strong> is triggered.</p></td></tr><tr><td><p><strong>Include instances from previous phases</strong></p></td><td><p>If you are using this verification step in a multi-phase deployment, select this checkbox to include instances used in previous phases when collecting data. Do not apply this setting to the first phase in a multi-phase deployment.</p></td></tr><tr><td><p><strong>Wait interval before execution</strong></p></td><td><p>Set how long the deployment process should wait before executing the verification step.</p></td></tr></tbody></table><p></p><h3>Notes</h3><ul><li>Depending on the custom metric provider you select, you might need to provide different information to the <strong>Metric Collections</strong> section. For example, you might need to provide a hostname for the <strong>Guide from an example</strong> popover to use to retrieve data. The hostname will be the host/container/pod/node name where the artifact is deployed. In you look in the JSON for the deployment environment, the hostname is typically the <strong>name</strong> label under the <strong>host</strong> label.</li></ul><p></p><ul><li>The <strong>Compare With Previous Run</strong> option is used for Canary deployments where the second phase is compared to the first phase, and the third phase is compared to the second phase, and so on. Do not use this setting in a single phase workflow or in the first phase of a multi-phase workflow.</li></ul><h3>Next Step</h3><ul><li> <a href="/article/facqx6j76n-3-datadog-as-a-custom-apm">5 - Datadog as a Custom APM</a></li></ul><p></p>
  slug: 2-verify-deployments-with-custom-apms
  tags:
  - Verification Provider
  - verification
  - APM
  - application performance monitoring
  - Deployment Verification
  - setup
  - log
  - Workflow
  - Metrics Provider
  - risk analysis
  is_live: true
