<p>This topic lists and describes the Enterprise Hub Experiments that are available when you use Harness Chaos Engineering.</p><div class="note-callout">For Litmus ChaosHub, see <a href="https://github.com/litmuschaos/chaos-charts" target="_blank">https://github.com/litmuschaos/chaos-charts</a>.</div><p>For information on using these chaos experiments, see <a href="/article/v64rj2maiz">Harness Chaos Engineering Basics</a> and <a href="/article/da85u0cbhx">Harness Chaos Engineering Quickstart</a>.</p><h3>Amazon Web Services (AWS)</h3><p>The following experiments are available for AWS.</p><h4>AWS SSM Chaos By ID</h4><p>Name: <strong>aws-ssm-chaos-by-id</strong>.</p><p>AWS SSM Chaos By ID contains chaos to disrupt the state of infra resources. The experiment can induce chaos on AWS resources using the Amazon SSM Run Command.</p><p>Harness performs chaos experiments on resources using AWS Systems Manager (SSM) documents to define the actions performed by Systems Manager on your managed instances (with SSM agent installed).</p><ul><li>Causes chaos on AWS EC2 instances with given instance Id(s) using SSM documents for total chaos duration with the specified chaos interval.</li><li>Tests deployment sanity (replica availability and uninterrupted service) and recovery workflows of the target application pod (if provided).</li></ul><p></p><h4>AWS SSM Chaos By Tag</h4><p>Name: <strong>aws-ssm-chaos-by-tag</strong>.</p><p>AWS SSM Chaos By Tag contains chaos to disrupt the state of infra resources. The experiment can induce chaos on AWS resources using Amazon SSM Run Command</p><p>Harness performs chaos experiments on resources by using AWS Systems Manager (SSM) documents to define the actions performed by Systems Manager on your managed instances (with SSM agent installed).</p><ul><li>Causes chaos on AWS EC2 instances with given instance tags using SSM documents for total chaos duration with the specified chaos interval.</li><li>Tests deployment sanity (replica availability and uninterrupted service) and recovery workflows of the target application pod (if provided).</li></ul><p></p><h4>EBS Loss By ID</h4><p>Name: <strong>ebs-loss-by-id</strong>.</p><p>EBS Loss By ID contains chaos to disrupt state of infra resources. The experiment can induce EBS volume loss against specified applications for given EBS Volume(s).</p><ul><li>Causes EBS volume loss from node or EC2 instance for a certain chaos interval from total chaos duration.</li><li>Tests deployment sanity (replica availability and uninterrupted service) and recovery workflows of the application pod.</li></ul><p></p><h4>EBS Loss By Tag</h4><p>Name: <strong>ebs-loss-by-tag</strong>.</p><p>EBS Loss By Tag contains chaos to disrupt state of infra resources. The experiment can induce EBS volume loss against specified applications for given EBS volume tag.</p><ul><li>Causes EBS volume loss by tag from node or EC2 instance for certain chaos interval from total chaos duration.</li><li>Tests deployment sanity (replica availability and uninterrupted service) and recovery workflows of the application pod.</li></ul><p></p><h4>EC2 CPU Hog</h4><p>Name: <strong>ec2-cpu-hog</strong>.</p><p>EC2 CPU hog experiment contains chaos to disrupt the state of EC2 instances. Experiments can inject CPU hog on the target EC2 instances.</p><ul><li>Causes CPU hog in the target EC2 instances.</li><li>Checks the performance of the application running on the EC2 instance when subject to CPU stress.</li></ul><p></p><h4>EC2 IO Stress</h4><p>Name: <strong>ec2-io-stress</strong>.</p><p>EC2 IO stress experiment contains chaos to disrupt the state of the EC2 instance. Experiments can inject IO stress on the target EC2 instances.</p><ul><li>Causes IO stress in the target EC2 instances.</li><li>Checks the performance of the application running on the EC2 instance when subject to IO stress.</li></ul><p></p><h4>EC2 Memory Hog</h4><p>Name: <strong>ec2-memory-hog</strong>.</p><p>EC2 memory hog experiment contains chaos to disrupt the state of the EC2 instance. Experiments can inject memory hog on the target EC2 instances.</p><ul><li>Causes memory hog in the target EC2 instances.</li><li>Checks the performance of the application running on the EC2 instance when subject to memory stress.</li></ul><h4>EC2 Stop by Id</h4><p>Name: <strong>ec2-stop-by-id</strong>.</p><p>This experiment causes termination of an EC2 instance for a certain chaos duration.</p><ul><li>Causes termination of an EC2 instance using the instance Id before bringing it back to a running state after the specified chaos duration.</li><li>Helps check the performance of the application on the EC2 instance.</li></ul><h4>EC2 Stop by Tag</h4><p>Name: <strong>ec2-stop-by-tag</strong>.</p><p>This experiment causes termination of an EC2 instance for a certain chaos duration.</p><ul><li>Causes termination of an EC2 instance using instance tags before bringing it back to running state after the specified chaos duration.</li><li>It helps to check the performance of the application on the EC2 instance.</li></ul><h4>ECS Agent Stop</h4><p>Name: <strong>ecs-agent-stop</strong>.</p><p>Stops all the ECS agent container running on all the Container Instance of the ECS cluster.</p><h4>ECS Container CPU Hog</h4><p>Name: <strong>ecs-container-cpu-hog</strong>.</p><p>Contains chaos to disrupt the state of AWS ECS service. Experiments can inject CPU hog against specified tasks running on the ECS cluster.</p><ul><li>Causes CPU hog in the task container running on the ECS Cluster.</li><li>It helps to check the performance of the task/application running on the ECS cluster when subject to CPU hog.</li></ul><h4>ECS Container IO Stress</h4><p>Name: <strong>ecs-container-io-stress</strong>.</p><p>ECS container IO stress contains chaos to disrupt the state of AWS ECS service. Experiments can inject IO stress against specified tasks running on the ECS cluster.</p><ul><li>Causes IO stress in the task container running on the ECS Cluster.</li><li>Checks the performance of the task/application running on the ECS cluster when subject to IO stress.</li></ul><h4>ECS Container Memory Hog</h4><p>Name: <strong>ecs-container-memory-hog</strong>.</p><p>ECS container memory hog contains chaos to disrupt the state of AWS ECS service. Experiments can inject memory hog against specified tasks running on the ECS cluster.</p><ul><li>Causes memory hog in the task container running on the ECS Cluster.</li><li>Checks the performance of the task/application running on the ECS cluster when subject to memory hog.</li></ul><h4>ECS Container Network Latency</h4><p>Name: <strong>ecs-container-network-latency</strong>.</p><p>ECS container network latency contains chaos to disrupt the state of AWS ECS service. Experiments can inject network latency failures against specified tasks running on the ECS cluster.</p><ul><li>Causes latency to the task container running on the ECS Cluster.</li><li>Checks the performance of the task/application running on the ECS cluster when subject to network latency.</li></ul><h4>ECS Container Network Loss</h4><p>Name: <strong>ecs-container-network-loss</strong>.</p><p>ECS container network loss contains chaos to disrupt the state of AWS ECS service. Experiments can inject network loss failures against specified tasks running on the ECS cluster.</p><ul><li>Causes loss of access to the task container running on the ECS Cluster.</li><li>It helps to check the performance of the task/application running on the ecs cluster when subject to network loss.</li></ul><h4>ECS Instance Stop</h4><p>Name: <strong>ecs-instance-stop</strong>.</p><p>ECS instance stop contains chaos to disrupt the state of EC2 instance associated with ECS cluster. This experiment can inject chaos to stop the EC2 instances that are running the ECS tasks and restarts it after the given chaos duration.</p><ul><li>Checks the performance of the task/application running on the EC2 instance of the ECS cluster.</li></ul><h4>ELB Availability Zone Down</h4><p>Name: <strong>elb-az-down</strong>.</p><p>The experiment causes detachment of the target availability zone(s) from an ELB that might result in service (associated with target ELB) hindrance/unavailability for the specific zone for a certain chaos duration.</p><h3>Azure</h3><p>The following experiments are available for Microsoft Azure.</p><h4>Azure Disk Loss</h4><p>Name: <strong>azure-disk-loss</strong>.</p><p>This experiment causes the detachment of the disk from the VM for a certain chaos duration</p><ul><li>Causes detachment of the disk from the VM and then reattachment of the disk to the VM.</li><li>Checks the performance of the application on the instance.</li></ul><h4>Azure Instance CPU Hog</h4><p>Name: <strong>azure-instance-cpu-hog</strong>.</p><p>Azure instance CPU hog contains chaos to disrupt the state of Azure instance. Experiments can inject CPU hog on the target Azure instances.</p><ul><li> Causes CPU hog in the target Azure instances.</li><li> Checks the performance of the application running on the azure instance when subject to cpu stress.</li></ul><h4>Azure Instance IO Stress</h4><p>Name: <strong>azure-instance-io-stress</strong>.</p><p>Azure instance IO stress contains chaos to disrupt the state of Azure instance. Experiments can inject IO stress on the target Azure instances.</p><ul><li>Causes IO stress in the target Azure instances.</li><li>Checks the performance of the application running on the Azure instance when subject to IO stress.</li></ul><h4>Azure Instance Memory Hog</h4><p>Name: <strong>azure-instance-memory-hog</strong>. </p><p>Azure instance memory hog contains chaos to disrupt the state of Azure instance. Experiments can inject memory hog on the target Azure instances.</p><p>Causes memory hog in the target Azure instances.</p><p>Checks the performance of the application running on the Azure instance when subject to memory hog.</p><h4>Azure Instance Stop</h4><p>Name <strong>azure-instance-stop</strong>.</p><p>Azure instance stop contains chaos to disrupt the state of Azure instance. Experiments can inject Azure instances stop for a certain chaos duration.</p><ul><li>Checks the performance of the application/processes running on the Azure instance when subject to instance stop.</li></ul><h4>Azure Web App Access Restrict</h4><p>Name: <strong>azure-web-app-access-restrict</strong>.</p><p>Azure Web App Access Restrict contains chaos to disrupt the state of Azure Web App. Experiments can inject an access restriction on the target Azure web application.</p><ul><li>Causes the access rule for an azure web app.</li><li>Checks the scenario when a web app is under access restrictions.</li></ul><h4>Azure Web App Stop</h4><p>Name: <strong>azure-web-app-stop</strong>.</p><p>Azure Web App Stop contains chaos to disrupt the state of Azure web application. Experiments can inject access loss on the target web app for a certain duration.</p><h3>Google Cloud Platform (GCP)</h3><p>The following experiments are available for GCP.</p><h4>GCP VM Disk Loss by Label</h4><p>Name: <strong>gcp-vm-disk-loss-by-label</strong>.</p><p>Causes loss of a non-boot storage persistent disk from a GCP VM instance filtered by a label for a specified duration before attaching them back.</p><h4>GCP VM Disk Loss</h4><p>Name: <strong>gcp-vm-disk-loss</strong>.</p><p>Causes loss of a non-boot storage persistent disk from a GCP VM instance for a specified duration before attaching them back.</p><h4>GCP VM Instance Stop by Label</h4><p>Name: <strong>gcp-vm-instance-stop-by-label</strong>.</p><p> Stops GCP VM instances and GKE nodes filtered by a label for a specified duration and later restarts them.</p><h4>GCP VM Instance Stop</h4><p>Name: <strong>gcp-vm-instance-stop</strong>.</p><p>Stops GCP VM instances and GKE nodes for a specified duration and later restarts them.</p><h3>Kubernetes</h3><p>The following experiments are available for platform-agnostic Kubernetes.</p><h4>Container Kill</h4><p>Name: <strong>container-kill</strong>.</p><p>Container kill contains chaos to disrupt state of Kubernetes resources. Experiments can inject random container delete failures against specified application.</p><ul><li>Executes SIGKILL on containers of random replicas of an application deployment.</li><li>Tests deployment sanity (replica availability and uninterrupted service) and recovery workflows of the application pod.</li></ul><h4>Disk Fill</h4><p>Name: <strong>disk-fill</strong>.</p><p> Disk fill contains chaos to disrupt state of Kubernetes resources.</p><ul><li>Causes (forced/graceful) disk stress by filling up the ephemeral storage of the Pod using one of it containers.</li><li>Causes Pod to get evicted if the Pod exceeds it ephemeral storage limit.</li><li>Tests the ephemeral storage limits to ensure those parameters are sufficient.</li></ul><p></p><h4>Docker Service Kill</h4><p>Name: <strong>docker-service-kill</strong>.</p><p>Kills Docker service gracefully for a certain chaos duration.</p><p>Causes replicas to be evicted or becomes unreachable on account of nodes turning unschedulable (Not Ready) due to Docker service kill.</p><p> The application node should be healthy once chaos is stopped and the services are re-accessible.</p><p></p><h4>Kubelet Service Kill</h4><p>Name: <strong>kubelet-service-kill</strong>.</p><p>Kills kubelet service gracefully for a certain chaos duration.</p><p>Causes replicas to be evicted or becomes unreachable on account on nodes turning unschedulable (Not Ready) due to kubelet service kill.</p><p> The application node should be healthy once chaos is stopped and the services are re-accessible.</p><h4>Node CPU Hog</h4><p>Name: <strong>node-cpu-hog</strong>.</p><p>Node CPU hog contains chaos to disrupt the state of Kubernetes resources. Experiments can inject a CPU spike on a node where the application pod is scheduled.</p><ul><li>CPU hog on a particular node where the application deployment is available.</li><li>After testing, the recovery should be manual for the application pod and node in case they are not in an appropriate state.</li></ul><p></p><h4>Node Drain</h4><p>Name: <strong>node-drain</strong>.</p><p>Drain the node where application pod is scheduled.</p><h4>Node IO Stress</h4><p>Name: <strong>node-io-stress</strong>.</p><p>This experiment causes disk stress on the Kubernetes node. The experiment aims to verify the resiliency of applications that share this disk resource for ephemeral or persistent storage purposes.</p><p>Disk stress on a particular node filesystem where the application deployment is available.</p><p>The amount of disk stress can be either specified as the size in percentage of the total free space on the file system or simply in Gigabytes(GB).</p><p></p><h4>Node Memory Hog</h4><p>Name: <strong>node-memory-hog</strong>.</p><p>Kubernetes Node memory hog contains chaos to disrupt the state of Kubernetes resources. Experiments can inject a memory spike on a node where the application pod is scheduled.</p><p>Memory hog on a particular node where the application deployment is available.</p><p>After the test, the recovery should be manual for the application pod and node in case they are not in an appropriate state.</p><h4>Node Network Latency</h4><p>Name: <strong>node-network-latency</strong>.</p><p>Injects network packet latency on the provided nodes for a certain chaos duration.</p><h4>Node Network Loss</h4><p>Name: <strong>node-network-loss</strong>.</p><p>Injects network packet loss on the provided nodes for a certain chaos duration.</p><h4>Node Taint</h4><p>Name: <strong>node-taint</strong>.</p><p>Taint the node where application pod is scheduled.</p><h4>Pod Autoscaler</h4><p>Name: pod-autoscaler.</p><p>Checks the ability of nodes to accommodate the number of replicas a given application pod.</p><p>This experiment can be used for other scenarios as well, such as for checking the Node auto-scaling feature. For example, check if the pods are successfully rescheduled within a specified period in cases where the existing nodes are already running at the specified limits.</p><h4>Pod CPU Hog Exec</h4><p>Name: <strong>pod-cpu-hog-exec</strong>.</p><p>Contains chaos to consume CPU resources of specified containers in Kubernetes pods.</p><ul><li>Causes high CPU resource consumption utilizing one or more cores by triggering md5sum commands.</li><li>The application pod should be healthy once chaos is stopped. Expectation is that service requests should be served despite chaos.</li></ul><h4>Pod CPU Hog</h4><p>Name: <strong>pod-cpu-hog</strong>.</p><p>Contains chaos to consume CPU resources of specified containers in Kubernetes pods.</p><ul><li>Causes CPU resource consumption on specified application containers using cgroups and litmus nsutil which consume CPU resources of the given target containers.</li><li>Tests the application&#39;s resilience to potential slowness/unavailability of some replicas due to high CPU load.</li><li>The application pod should be healthy once chaos is stopped. Expectation is that service-requests should be served despite chaos.</li></ul><p></p><h4>Pod Delete</h4><p>Name: <strong>pod-delete</strong>.</p><p>Pod delete contains chaos to disrupt state of Kubernetes resources. Experiments can inject random pod delete failures against specified application.</p><ul><li>Causes (forced/graceful) pod failure of random replicas of an application deployment.</li><li>Tests deployment sanity (replica availability &amp; uninterrupted service) and recovery workflows of the application pod.</li></ul><p></p><h4>Pod DNS Error</h4><p>Name: <strong>pod-dns-error</strong>.</p><p>Pod DNS Error injects DNS failure/error in target pod containers.</p><h4>Pod DNS Spoof</h4><p>Name: <strong>pod-dns-spoof</strong>.</p><p>Spoofs particular DNS requests in target pod container to desired target hostnames.</p><h4>Pod HTTP Latency</h4><p>Name: <strong>pod-http-latency</strong>.</p><p>Contains chaos to disrupt http requests of Kubernetes pods. This experiment can inject random http response delays on the app replica pods.</p><ul><li>Causes flaky access to application replica by injecting HTTP response delay using toxiproxy.</li><li>The application pod should be healthy once chaos is stopped. Service-requests should be served despite chaos.</li></ul><p></p><h4>Pod HTTP Modify Body</h4><p>Name: <strong>pod-http-modify-body</strong>.</p><p>Contains chaos to disrupt http requests of Kubernetes pods. This experiment can modify the body of the response from the service targeted.</p><ul><li>Causes modification of response body of the HTTP request.</li><li>The application pod should be healthy once chaos is stopped. Service-requests should be served despite chaos.</li></ul><h4>Pod HTTP Modify Header</h4><p>Name: <strong>pod-http-modify-header</strong>.</p><p>Contains chaos to disrupt HTTP requests of Kubernetes pods. This experiment can modify headers of incoming requests or the response from the service targeted.</p><ul><li>Causes modification of request/response headers of the HTTP request.</li><li>The application pod should be healthy once chaos is stopped. Service-requests should be served despite chaos.</li></ul><p></p><h4>Pod HTTP Reset Peer</h4><p>Name: pod-http-reset-peer.</p><p>Contains chaos to disrupt http requests of Kubernetes pods. This experiment can stop outgoing http requests by resetting the TCP connection on the service targeted.</p><ul><li>Causes connection failure (connection reset by peer) of the HTTP request.</li><li>The application pod should be healthy once chaos is stopped. Service-requests should be served despite chaos.</li></ul><p></p><h4>Pod HTTP Status Code</h4><p>Name: <strong>pod-http-status-code</strong>.</p><p>Contains chaos to disrupt http requests of Kubernetes pods. This experiment can modify the status code of the response on the service targeted.</p><ul><li>Causes modification of status code of the HTTP request.</li><li>The application pod should be healthy once chaos is stopped. Service-requests should be served despite chaos.</li></ul><p></p><h4>Pod IO Stress</h4><p>Name: <strong>pod-io-stress</strong>.</p><p>This experiment causes disk stress on the application pod. The experiment aims to verify the resiliency of applications that share this disk resource for ephemeral or persistent storage purposes.</p><ul><li>Consumes the disk available by executing filesystem IO stress as available memory or by providing the value in GB.</li><li>The application pod should be healthy once chaos is stopped. Expectation is that service-requests should be served despite chaos.</li></ul><p></p><h4>Pod Memory Hog Exec</h4><p>Name: <strong>pod-memory-hog-exec</strong>.</p><p>Contains chaos to consume Memory resources of specified containers in Kubernetes pods.</p><ul><li>Consumes the memory specified by executing a dd command against special files /dev/zero(input) and /dev/null(output).</li><li>The application pod should be healthy once chaos is stopped. Expectation is that service-requests should be served despite chaos.</li></ul><p></p><h4>Pod Memory Hog</h4><p>Name: <strong>pod-memory-hog</strong>.</p><p>Contains chaos to consume memory resources of specified containers in Kubernetes pods.</p><ul><li>Causes memory resource consumption on specified application containers using cgroups and litmus nsutil that consume memory resources of the given target containers.</li><li>Can test the application&#39;s resilience to potential slowness/unavailability of some replicas due to high memory load</li><li>The application pod should be healthy once chaos is stopped. Expectation is that service-requests should be served despite chaos.</li></ul><p></p><h4>Pod Network Corruption</h4><p>Name <strong>pod-network-corruption</strong>.</p><p>Contains chaos to disrupt network connectivity to Kubernetes pods. Experiments can inject percentage packet corruption on the app replica pods.</p><ul><li>Causes packet corruption of application replica by injecting packet corruption using pumba.</li><li>The application pod should be healthy once chaos is stopped. Service-requests should be served (say, via alternate replicas) despite chaos.</li></ul><p></p><h4>Pod Network Duplication</h4><p>Name: <strong>pod-network-duplication</strong>.</p><p>Contains chaos to disrupt network connectivity to Kubernetes pods. Experiments can inject percentage packet duplication on the app replica pods.</p><ul><li> Causes lossy access to application replica by injecting packet duplication using pumba.</li><li> The application pod should be healthy once chaos is stopped. Service-requests should be served (say, via alternate replicas) despite chaos.</li></ul><p></p><h4>Pod Network Latency</h4><p>Name: <strong>pod-network-latency</strong>.</p><p>Contains chaos to disrupt network connectivity of Kubernetes pods. Experiments can inject random network delays on the app replica pods.</p><ul><li>Causes flaky access to application replica by injecting network delay using pumba.</li><li>The application pod should be healthy once chaos is stopped. Service-requests should be served despite chaos.</li></ul><p></p><h4>Pod Network Loss</h4><p>Name: <strong>pod-network-loss</strong>.</p><p>Contains chaos to disrupt network connectivity to Kubernetes pods. Experiments can inject percentage packet loss on the app replica pods.</p><ul><li>Causes loss of access to application replica by injecting packet loss using pumba.</li><li>The application pod should be healthy once chaos is stopped. Service-requests should be served (say, via alternate replicas) despite chaos.</li></ul><p></p><h4>Pod Network Partition</h4><p>Name: <strong>pod-network-partition</strong>.</p><p>Contains chaos to disrupt network connectivity to Kubernetes pods. Experiments can inject complete egress/ingress network loss based on label and namespace selectors.</p><ul><li>The application pod should be healthy once chaos is stopped. Service-requests should be served (say, via alternate replicas) despite chaos.</li></ul><p></p><h3>VMware</h3><p>The following experiments are available for VMware.</p><h4>VM Poweroff</h4><p>Name: <strong>vm-poweroff</strong>.</p><p>Powers off the target VMs for a certain chaos duration and bring back to running state, this will allow the user to verify the resiliency of the process/application that are running on the target instance.</p><p></p><h4>VM Process Kill</h4><p>Name: <strong>vm-process-kill</strong>.</p><p>Kills provided process in target VMs for a certain chaos duration, this will allow the user to verify the process/application resiliency running on the targeted VMs.</p><h4>VM Service Stop</h4><p>Name: <strong>vm-service-stop</strong>.</p><p>This chaos scenario comprised of one chaos experiment that stops services in the target VMware VM for a certain chaos duration, this will allow the user to verify the resiliency of the process/application running on the targeted VMs.</p><p></p><h4>VMware Disk Loss</h4><p>Name: <strong>vmware-disk-loss</strong>.</p><p>Causes the detachment of Virtual Disks attached to a VM for a specified duration of time and later attaches them back to the VM.</p><h4>VMware Network Latency</h4><p>Name: <strong>vmware-network-latency</strong>.</p><p>Contains chaos to disrupt network connectivity of the VM(s), it causes flaky access to the application/services by injecting network delay.</p><h4>VMware Network Loss</h4><p>Name: <strong>vmware-network-loss</strong>.</p><p>Contains chaos to disrupt network connectivity of the VM(s), it causes flaky access to the application/services by injecting network loss.</p><p></p><p></p>