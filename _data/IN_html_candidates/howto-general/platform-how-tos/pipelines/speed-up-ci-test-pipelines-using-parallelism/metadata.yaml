type: article
article_id: kce8mgionj
user_id: xwmdbyp4x8
category_id: kncngmy17o
author:
  name: Doug Bothwell
  profile_image: https://www.gravatar.com/avatar/120de2cc624d7903cf3d83b86d0f1b5e?d=mm&s=150
title: Speed Up CI Test Pipelines Using Parallelism
slug: speed-up-ci-test-pipelines-using-parallelism
description: Use parallelism to to run your build tests in parallel. This is one of
  the looping strategies available in Harness pipelines. Parallelism is useful whenever
  there is a need to run a step or a stage multiple times in parallel.
short_version: Use parallelism to to run your build tests in parallel. This is one
  of the looping strategies available in Harness pipelines. Parallelism is useful
  whenever there is a need to run a step or a stage multiple times in parallel.
tags: []
show_toc: true
is_private: false
is_published: true
is_featured: false
stale_status:
  is_stale: false
  reason: ""
  source: API
  triggered_at: 2022-08-23T20:21:43.400969Z
  expires_at: null
permission_groups: []
multilingual:
- language_code: en
  title: Speed Up CI Test Pipelines Using Parallelism
  description: Use parallelism to to run your build tests in parallel. This is one
    of the looping strategies available in Harness pipelines. Parallelism is useful
    whenever there is a need to run a step or a stage multiple times in parallel.
  short_version: Use parallelism to to run your build tests in parallel. This is one
    of the looping strategies available in Harness pipelines. Parallelism is useful
    whenever there is a need to run a step or a stage multiple times in parallel.
  body: '<div class="note-callout">Currently, this feature is behind a Feature Flag.
    Contact <a href="mailto:support@harness.io" target="_blank">Harness Support</a> to
    enable the feature.</div><p>The more tests you run, the longer it takes for them
    to complete if run sequentially. To reduce test cycle time, you can split your
    tests and run them across multiple groups at the same time. </p><p><em>P</em><em>arallelism</em> is
    one of the <a href="https://docs.harness.io/article/eh4azj73m4">looping strategies</a>
    available in Harness pipelines. Parallelism is useful whenever you can split a
    step or stage into multiple groups and run them at the same time. </p><p>Parallelism
    is one of the <a href="https://docs.harness.io/article/g3m7pjq79y" target="_blank">available
    methods</a> you can use to speed up your CI builds.</p><h3>Key concepts: parallelism
    and test splitting</h3><p>Many pipelines are set up to run a set of tests with
    every new commit. When you <a href="#workflow-description">set up parallelism</a>
    in your pipeline, you specify the following:</p><ol><li>How many copies of the
    stage or step to run (<a href="#define-parallelism-strategy"><code>parallelism</code></a>
    field).</li><li>How to split your tests into groups (<a href="#ddefine-test-splitting"><code>split_tests</code></a>
    command). This command splits the tests as evenly as possible to ensure the fastest
    overall test time. You can split by file size or by file timing.</li></ol><p>The
    following figure illustrates how parallelism can speed up your CI pipelines. The
    first time you run with parallelism, the pipeline splits the tests by file size
    and collects timing data for all tests. You can then split your tests by time
    and speed up your pipeline even further. Every build optimizes the splitting based
    on the most recent timing data.</p><p><strong>Figure 1: Parallelism and Test Times</strong></p><figure><img
    src="https://files.helpdocs.io/kw8ldg1itf/articles/f2qxm48wuh/1660489424898/parallelism-final.png"
    style="display:block;margin-left:0;margin-right:auto" data-hd-align="left"/></figure><h3>YAML
    stage with parallelism</h3><p>Parallelism can be set on both steps and stages. </p><p>The
    following snippet shows a YAML definition of a Run step that uses <a href="https://docs.pytest.org/">pytest</a>
    to split tests into four test groups running in parallel.</p><pre class="hljs
    yaml"># Use &#34;run&#34; step type<br/>- step:<br/>      type: Run    <br/>      name:
    Run Pytests<br/>      identifier: Run_Pytests<br/># Enable parallelism strategy
    <br/>      strategy:            <br/>          parallelism: 4    # Number of parallel
    runs<br/>          maxConcurrency: 2 # (optional) Limit the number of parallel
    runs <br/>      spec:<br/>          connectorRef: $dockerhub_connector<br/>          image:
    python:latest<br/>          shell: Sh<br/># Store the current index and total
    runs in environment variables<br/>          envVariables:  <br/>              HARNESS_NODE_INDEX:
    &lt;+strategy.iteration&gt;  # index of current run<br/>              HARNESS_NODE_TOTAL:
    &lt;+strategy.iterations&gt; # total runs<br/>          command: |-<br/>              pip
    install -r requirements.txt<br/># Define splitting strategy and generate a list
    of test groups<br/>              FILES=`/addon/bin/split_tests --glob &#34;**/test_*.py&#34;
    \<br/>                     --split-by file_timing \<br/>                     --split-index
    ${HARNESS_NODE_INDEX} \<br/>                     --split-total ${HARNESS_NODE_TOTAL}`<br/>              echo
    $FILES<br/># Run tests with the test-groups string as input<br/>              pytest
    -v --junitxml=&#34;result_&lt;+strategy.iteration&gt;.xml&#34; $FILES<br/># Publish
    JUnit test reports to Harness <br/>         reports:  <br/>              type:
    JUnit <br/>              spec:<br/>                  paths:   # Generate unique
    report for each iteration<br/>                      - &#34;**/result_&lt;+strategy.iteration&gt;.xml&#34;
    <br/>      failureStrategies: []</pre><h3>Important notes </h3><ul><li>Please
    consider any resource constraints in your build infrastructure when using parallelism.
    To learn more, go to <a href="https://docs.harness.io/article/q7i0saqgw4" target="_blank">Best
    Practices for Looping Strategies</a>.</li><li>You can implement a parallelism
    strategy for an entire stage or for individual steps within a stage.</li><li>If
    you are implementing parallelism in a step rather than a stage, you need to make
    sure that each test-group step generates a report with a unique filename to avoid
    conflicts.<br/>You can do this using the <code>&lt;+strategy.iteration&gt;</code>
    variable, which is the index of the current test group run. This index is in the
    range of <code>0</code> to <code>parallelism- 1</code>.</li><li>If you want to
    publish your test results, you must ensure that your output files are in <a href="https://junit.org/junit5/"
    target="_blank">JUnit</a> XML format. How you publish your test results depends
    on the specific language, test runner, and formatter used in your repo.<br/>For
    more information, go to <a href="#publish-test-results">Publish test reports</a>.</li></ul><h3
    id="workflow-description">Set up parallelism in a pipeline</h3><p>The following
    steps describe the high-level workflow for setting up parallelism in a pipeline.
    </p><ol><li>Enable parallelism and specify the number of jobs you want to in parallel.
    Go to <a href="#define-parallelism-strategy">Define the parallelism strategy</a>.</li><li>Define
    the following environment variables in the stage where you run your parallelism
    strategy:<ul><li><code>HARNESS_NODE_TOTAL</code> = <code>&lt;+strategy.iterations&gt;</code>
    — The total number of iterations in the current Stage or Step.</li><li><code>HARNESS_NODE_INDEX</code>
    = <code>&lt;+strategy.iterations&gt;</code> — The index of the current test run.
    This index is in the range of <code>0</code> to <code>parallelism</code><code>-
    1</code>.</li></ul>. This snippet shows how you can define and use these variables
    in the YAML editor:<pre>- step:   <br/>     ....<br/>     envVariables:      
    <br/>          HARNESS_NODE_INDEX: &lt;+strategy.iteration&gt; <br/>          HARNESS_NODE_TOTAL:
    &lt;+strategy.iterations&gt; <br/>     command: |-       <br/>          pip install
    -r requirements.txt       <br/>          FILES=`/addon/bin/split_tests --glob
    &#34;**/test_*.py&#34; \<br/>                --split-by file_size \<br/>                --split-index
    ${HARNESS_NODE_INDEX} \<br/>                --split-total=${HARNESS_NODE_TOTAL}`
          <br/>          pytest -v --junitxml=&#34;result_${HARNESS_NODE_INDEX}.xml&#34;
    $FILES <br/>          echo &#34;$HARNESS_NODE_TOTAL runs using file list $FILES&#34;
    </pre>To define these attributes in the Pipeline Studio, go to the step that implements
    the parallelism strategy. Then go to <strong>Optional Configuration</strong> &gt;
    <strong>Environment Variables</strong>.</li><li>Set up the split_tests command
    with the splitting criteria based on file size (<code>--split-by file_size</code>).
    Go to <a href="#define-test-splitting">Define test splitting</a>.</li><li>Define
    your test reports. Your reports must be in JUnit format. Go to <a href="#publish-test-results">Publish
    test reports</a>.</li><li>Run your Pipeline to make sure all your Steps complete
    successfully. You can see the parallel copies of your Step running in the Build
    UI.<br/><strong>Figure 2: Parallel steps in a build</strong><figure><img src="https://files.helpdocs.io/kw8ldg1itf/articles/smx0bijd90/1660250471764/first-run-build.png"
    style="max-height:50%;max-width:50%;display:block;margin-left:0;margin-right:auto"
    data-hd-height="50%" data-hd-width="50%" data-hd-align="left"/></figure></li><li>When
    the build finishes, go to the Tests tab and view your results. You can view results
    for each parallel run using the pull-down.<br/><strong>Figure 3: View results
    for individual runs</strong><figure><img src="https://files.helpdocs.io/kw8ldg1itf/articles/smx0bijd90/1660250515845/first-run-test-results.png"
    style="display:block;margin-left:0;margin-right:auto" data-hd-align="left"/></figure></li><li>Now
    that Harness has collected timing data, you can split your tests by time and reduce
    your build times further. Go to <a href="#define-test-splitting">Define test splitting</a>.</li></ol><h3
    id="define-parallelism-strategy">Define the parallelism strategy</h3><p>The <code>parallelism</code>
    value defines how many steps you want to run in parallel. In general, a higher
    value means a faster completion time for all tests. The primary restraint is the
    resource availability in your build infrastructure. The YAML definition looks
    like this:</p><pre class="hljs yaml">- step:<br/>      ...<br/>      strategy:<br/>        parallelism:
    4</pre><p></p><h4>Defining parallelism in the Pipeline UI</h4><p>You can configure
    parallelism in the Pipeline Studio as well:</p><ol><li>In the Pipeline Studio,
    open the Step or Stage where you run your Tests and click the <strong>Advanced</strong>
    tab.</li><li>Under <strong>Looping Strategies</strong>, select <strong>Parallelism</strong>
    and define your strategy.<br/><strong>Figure 4: Define parallelism in a Run step</strong><figure><img
    src="https://files.helpdocs.io/kw8ldg1itf/articles/kce8mgionj/1660574108914/parallelism-in-run-step-ui.png"
    style="display:block;margin-left:0;margin-right:auto" data-hd-align="left"/></figure></li></ol><p></p><p><a
    href="#workflow-description">Parallelism Workflow</a></p><h3 id="define-test-splitting">Define
    test splitting</h3><p>You use the <code>split_tests</code> CLI command to define
    the set of tests you want to run. In the <strong>Command</strong> field of the
    step where you run your tests, you need to do the following:</p><ol><li>Configure
    the <code>split_tests</code> command to define how you want to split your tests.
    This command outputs a string of your test groups.</li><li>Run the test command
    with your test-groups string as input.</li></ol><pre># Generate a new set of grouped
    test files and output the file list to a string...<br/>/addon/bin/split_tests
    --glob &#34;**/test_*.py&#34; \<br/>          --split-by file_time \<br/>          --split-index
    ${HARNESS_NODE_INDEX} \<br/>          --split-total=${HARNESS_NODE_TOTAL}<br/>echo
    $FILES<br/># example output: test_api_2.py test_api_4.py test_api_6.py<br/><br/>#
    Then use the $FILES list as input to the test command--in this case, pytest:<br/>pytest
    -v --junitxml=&#34;result_${HARNESS_NODE_INDEX}.xml&#34; $FILES </pre><p></p><p>The
    <code>split_tests</code> command creates a new set of test files that is ordered
    based on your splitting criteria. This command takes the following as inputs:</p><ul><li>The
    set of all the tests you want to run (<code>--glob</code> argument).</li><li>The
    algorithm used to split the tests into groups (<code>--split-by</code> argument).</li><li>The
    run index and total number of runs. You should set these to the environment attributes
    you defined previously (<code>--split-index ${HARNESS_NODE_INDEX}</code> and <code>--split-total
    ${HARNESS_NODE_TOTAL}</code>).</li></ul><h4>Test splitting strategies</h4><p>The
    <code>split_tests</code> command allows you to define the criteria for splitting
    the tests. Harness supports the following options:</p><ul><li><code>--split-by
    file_size</code> - Split files into groups based on the size of individual files.</li><li><code>--split-by
    file_timing</code> — Split files into groups based on the test times of individual
    files. This defaults to <code>file_size</code> if timing information isn&#39;t
    available.</li></ul><div class="note-callout">You will get better performance
    if you split tests by timing rather than size. With <code>file_timing</code> selected,<code>split_tests</code>
    uses the most recent timing data to ensure that all parallel test runs finish
    at approximately the same time.</div><p><a href="#workflow-description">Parallelism
    Workflow</a></p><h3 id="publish-test-results">Define the test reports</h3><p>The
    <code>report</code> section in the Pipeline YAML defines how to publish your test
    reports. Here&#39;s an example:</p><pre class="hljs yaml">reports: <br/>   type:
    JUnit <br/>      spec: <br/>         paths: - &#34;**/result_${HARNESS_NODE_INDEX}.xml&#34;</pre><p></p><p>You
    need to do the following:</p><ul><li>Set up your test runner and formatter to
    publish your test reports in <a href="https://junit.org/junit5/" target="_blank">JUnit</a>
    XML format and to include filenames in the XML output. If you are using <a href="https://docs.pytest.org/"
    target="_blank">pytest</a>, for example, you can configure the report format by
    setting the <code>junit_family</code> in the pytest.ini file in your code repo:<br/><code>junit_family=xunit1</code><br/>Reporting
    setup and configurations depend on the specific test runner. Go to the external
    documentation for your specific runner to determine how to publish in the correct
    format.</li><li>If you are implementing parallelism in a step rather than a stage,
    you need to make sure that each test-group step generates a report with a unique
    filename.<br/>You can do this using the <code>&lt;+strategy.iteration&gt;</code>variable,
    which is the index of the current test run. This index is in the range of <code>0</code>
    to <code>parallelism</code><code>- 1</code>.</li></ul><p>You can configure your
    test reporting options in the pipeline YAML, as shown above, or in the Pipeline
    Studio. Go to the Run or Run Tests Step and configure the <strong>Report Paths</strong>
    field under Optional Configuration.</p><p><strong>Figure 6: Define Report Paths
    in a Run Step</strong></p><figure><img src="https://files.helpdocs.io/kw8ldg1itf/articles/kce8mgionj/1658587230180/report-paths-field.png"
    style="display:block;margin-left:0;margin-right:auto" data-hd-align="left"/></figure><p><a
    href="#workflow-description">Parallelism Workflow</a></p><h3>YAML pipeline example
    with parallelism</h3><p>The following example shows a full end-to-end pipeline
    with parallelism enabled.</p><details><summary>parallelism-pipeline-example.yml</summary><div><pre
    class="hljs yaml">pipeline:<br/>    name: parallelism-for-docs-v6<br/>    identifier:
    parallelismfordocsv6<br/>    projectIdentifier: myproject<br/>    orgIdentifier:
    myorg<br/>    tags: {}<br/>    properties:<br/>        ci:<br/>            codebase:<br/>                connectorRef:
    $GITHUB_CONNECTOR<br/>                repoName: testing-flask-with-pytest<br/>                build:
    &lt;+input&gt;<br/>    stages:<br/>        - stage:<br/>              name: Build
    and Test<br/>              identifier: Build_and_Test<br/>              type:
    CI<br/>              spec:<br/>                  cloneCodebase: true<br/>                  infrastructure:<br/>                      type:
    KubernetesDirect<br/>                      spec:<br/>                          connectorRef:
    $HARNESS_K8S_DELEGATE_CONNECTOR<br/>                          namespace: harness-delegate-ng<br/>                          automountServiceAccountToken:
    true<br/>                          nodeSelector: {}<br/>                          os:
    Linux<br/>                  execution:<br/>                      steps:<br/>                          -
    step:<br/>                                type: Run<br/>                                name:
    Run Pytests<br/>                                identifier: Run_Pytests<br/>                                strategy:<br/>                                    parallelism:
    4<br/>                                spec:<br/>                                    connectorRef:
    $DOCKERHUB_CONNECTOR<br/>                                    image: python:latest<br/>                                    shell:
    Sh<br/>                                    envVariables:<br/>                                        HARNESS_NODE_INDEX:
    &lt;+strategy.iteration&gt;<br/>                                        HARNESS_NODE_TOTAL:
    &lt;+strategy.iterations&gt;<br/>                                    command:
    |-<br/>                                        pip install -r requirements.txt<br/>                                        FILES=`/addon/bin/split_tests
    --glob &#34;**/test_*.py&#34; \<br/>                                               --split-by
    file_timing \<br/>                                               --split-index
    ${HARNESS_NODE_INDEX} \<br/>                                               --split-total=${HARNESS_NODE_TOTAL}`<br/>                                        echo
    $FILES<br/>                                        pytest -v --junitxml=&#34;result_${HARNESS_NODE_INDEX}.xml&#34;
    $FILES<br/>                                    reports:<br/>                                        type:
    JUnit<br/>                                        spec:<br/>                                            paths:<br/>                                                -
    &#34;**/result_${HARNESS_NODE_INDEX}.xml&#34;<br/>                                failureStrategies:
    []</pre></div></details><h3>See Also</h3><ul><li><a href="https://harness.helpdocs.io/article/g3m7pjq79y"
    target="_blank">Optimizing CI Build Times</a></li><li><a href="https://harness.helpdocs.io/article/eh4azj73m4"
    target="_blank">Looping Strategies Overview: Matrix, For Loop, and Parallelism</a></li><li><a
    href="https://docs.harness.io/article/q7i0saqgw4" target="_blank">Best Practices
    for Looping Strategies</a></li><li><a href="https://docs.harness.io/article/kay7z1bi01"
    target="_blank">Run a Stage or Step Multiple Times using a Matrix</a></li></ul><p></p>'
  slug: speed-up-ci-test-pipelines-using-parallelism
  tags: []
  is_live: true
